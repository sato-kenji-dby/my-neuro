diff --git a/README.md b/README.md
index 03deb46..d2f38c7 100644
--- a/README.md
+++ b/README.md
@@ -15,11 +15,15 @@ English Documentation: [English Version](./README_English.md)
 
 如果部署的时候遇到处理不了的bug可以前往此链接：http://fake-neuro.natapp1.cc
 
+
 向肥牛客服询问，它会指导你如何处理项目可能出现的bug 不过大多数情况下不会有什么bug！也许..
 
-同时我也会看后台的对话记录，看看它到底能不能解决问题，如果解决不了，我就会给它的数据库写上对应的
-处理方法，加载到它的知识库里面。下次遇到同样的bug大概率它自己就能解决了。所以，遇到问题就多多和肥牛聊天吧。
+![image](https://github.com/user-attachments/assets/703e8181-26b8-440f-a8d8-7102db56e6b4)
+
+
+如果肥牛客服解决不了，就点击页面右上角的这个"上传解决不了的报错"按键。点击后会直接把你和肥牛的对话记录发送到我的邮箱那去。
 
+我就可以看见对话记录，从而针对性的修复bug或者告诉肥牛如何解决这个bug 下次再遇到就可以解决了！！
 
 ## 计划清单（打✔的是已经实现的功能）
 
@@ -41,7 +45,7 @@ English Documentation: [English Version](./README_English.md)
 
 ### 扩展功能
 - [ ] 桌面控制：支持语音控制打开软件等操作
-- [ ] AI唱歌（功能由： [@jonnytri53](https://github.com/jonnytri53) 资金赞助开发，特此感谢）
+- [x] AI唱歌（功能由： [@jonnytri53](https://github.com/jonnytri53) 资金赞助开发，特此感谢）
 - [ ] 国外直播平台的接入
 - [x] 直播功能：可在哔哩哔哩平台直播
 - [ ] AI讲课：选择一个主题，让AI给你讲课。中途可提问。偏门课程可植入资料到数据库让AI理解
@@ -156,7 +160,7 @@ python tts_api.py -p 5000 -d cuda -s tts-model/merge.pth -dr tts-model/neuro/01.
 
 8.等待ASR和TTS都输出IP后，点击此链接下载zip文件：
 
-https://github.com/morettt/my-neuro/releases/download/v4.4.3/live-2d.zip
+https://github.com/morettt/my-neuro/releases/download/v4.4.5/live-2d.zip
 
 
 下载后解压是这样的，双击打开这个 肥牛.exe 文件
diff --git a/live-2d/app.js b/live-2d/app.js
deleted file mode 100644
index 4c632e9..0000000
--- a/live-2d/app.js
+++ /dev/null
@@ -1,1007 +0,0 @@
-// 导入所需模块
-const { EnhancedTextProcessor } = require('./js/tts-processor.js');
-const { ModelInteractionController } = require('./js/model-interaction.js');
-const { VoiceChatInterface } = require('./js/voice-chat.js');
-const { configLoader } = require('./js/config-loader.js');
-const { LiveStreamModule } = require('./js/LiveStreamModule.js');
-const { AutoChatModule } = require('./js/auto-chat.js');
-const { EmotionMotionMapper } = require('./js/emotion-motion-mapper.js');
-const { MCPClientModule } = require('./js/mcp-client-module.js');
-
-// 设置全局变量，用于模块间共享状态
-global.isPlayingTTS = false;
-global.isProcessingBarrage = false;
-global.isProcessingUserInput = false;
-
-const { ipcRenderer } = require('electron');
-const fs = require('fs');
-const path = require('path');
-const os = require('os');
-
-// 监听中断信号
-ipcRenderer.on('interrupt-tts', () => {
-    console.log('接收到中断信号');
-    logToTerminal('info', '接收到中断信号');
-    if (ttsProcessor) {
-        ttsProcessor.interrupt();
-    }
-    global.isPlayingTTS = false;
-    global.isProcessingUserInput = false;
-    global.isProcessingBarrage = false;
-    if (voiceChat && voiceChat.asrProcessor) {
-        setTimeout(() => {
-            voiceChat.resumeRecording();
-            console.log('ASR录音已恢复');
-            logToTerminal('info', 'ASR录音已恢复');
-        }, 200);
-    }
-    console.log('系统已复位，可以继续对话');
-    logToTerminal('info', '系统已复位，可以继续对话');
-});
-
-// 添加终端日志记录函数
-function logToTerminal(level, message) {
-    // 将日志格式化，包含时间戳
-    const timestamp = new Date().toISOString();
-    const formattedMsg = `[${timestamp}] [${level.toUpperCase()}] ${message}\n`;
-
-    // 直接写入到stderr（错误）或stdout（普通日志）
-    if (level === 'error') {
-        process.stderr.write(formattedMsg);
-    } else {
-        process.stdout.write(formattedMsg);
-    }
-
-    // 同时也记录到浏览器控制台（开发调试用）
-    if (level === 'error') {
-        console.error(message);
-    } else if (level === 'warn') {
-        console.warn(message);
-    } else {
-        console.log(message);
-    }
-}
-
-// 加载配置文件
-let config;
-try {
-    // 尝试加载配置
-    config = configLoader.load();
-    console.log('配置文件加载成功');
-    logToTerminal('info', '配置文件加载成功');
-} catch (error) {
-    // 如果加载失败，显示错误消息
-    console.error('配置加载失败:', error);
-    logToTerminal('error', `配置加载失败: ${error.message}`);
-    alert(`配置文件错误: ${error.message}\n请检查config.json格式是否正确。`);
-    // 让用户看到错误信息后手动关闭程序
-    throw error; // 抛出错误，终止程序执行
-}
-
-// 字幕管理
-let subtitleTimeout = null;
-
-// 更新鼠标穿透状态
-function updateMouseIgnore() {
-    // 如果鼠标不在可交互区域，则穿透
-    const shouldIgnore = !this.model.containsPoint(this.app.renderer.plugins.interaction.mouse.global);
-
-    ipcRenderer.send('set-ignore-mouse-events', {
-        ignore: shouldIgnore,
-        options: { forward: true } // 允许鼠标事件穿透
-    });
-}
-
-// 监听鼠标移动
-document.addEventListener('mousemove', updateMouseIgnore);
-
-// 监听聊天框相关事件，强制禁用穿透
-const chatInput = document.getElementById('chat-input');
-if (chatInput) {
-    // 鼠标进入聊天框时，禁用穿透
-    document.getElementById('text-chat-container').addEventListener('mouseenter', () => {
-        ipcRenderer.send('set-ignore-mouse-events', {
-            ignore: false,
-            options: { forward: false }
-        });
-    });
-
-    // 鼠标离开聊天框时，恢复检测
-    document.getElementById('text-chat-container').addEventListener('mouseleave', () => {
-        ipcRenderer.send('set-ignore-mouse-events', {
-            ignore: true,
-            options: { forward: true }
-        });
-    });
-
-    // 输入框聚焦时，强制禁用穿透（防止键盘输入失效）
-    chatInput.addEventListener('focus', () => {
-        ipcRenderer.send('set-ignore-mouse-events', {
-            ignore: false,
-            options: { forward: false }
-        });
-    });
-
-    // 输入框失焦时，恢复检测
-    chatInput.addEventListener('blur',() => {
-        ipcRenderer.send('set-ignore-mouse-events', {
-            ignore: true,
-            options: { forward: true }
-        });
-    });
-}
-
-function showSubtitle(text, duration = null) {
-    const container = document.getElementById('subtitle-container');
-    const subtitleText = document.getElementById('subtitle-text');
-
-    if (subtitleTimeout) {
-        clearTimeout(subtitleTimeout);
-        subtitleTimeout = null;
-    }
-
-    subtitleText.textContent = text;
-    container.style.display = 'block';
-
-    // 确保滚动到底部，显示最新内容
-    container.scrollTop = container.scrollHeight;
-
-    if (duration) {
-        subtitleTimeout = setTimeout(() => {
-            hideSubtitle();
-        }, duration);
-    }
-}
-
-function hideSubtitle() {
-    const container = document.getElementById('subtitle-container');
-    container.style.display = 'none';
-    if (subtitleTimeout) {
-        clearTimeout(subtitleTimeout);
-        subtitleTimeout = null;
-    }
-}
-
-// 创建模型交互控制器
-const modelController = new ModelInteractionController();
-let currentModel = null;
-const INTRO_TEXT = config.ui.intro_text || "你好，我叫fake neuro。";
-let voiceChat = null;
-let liveStreamModule = null; // 直播模块实例
-let autoChatModule = null;   // 自动对话模块实例
-let emotionMapper = null;    // 情绪动作映射器实例
-let mcpClientModule = null;  // MCP客户端模块实例
-
-// 弹幕队列管理
-let barrageQueue = [];
-// 注意：isPlayingTTS 和 isProcessingBarrage 现在是全局变量
-
-// 使用外部TTS处理器
-const ttsProcessor = new EnhancedTextProcessor(
-    config.tts.url,
-    (value) => modelController.setMouthOpenY(value),  // 音频数据回调
-    () => {
-        // TTS开始播放回调
-        global.isPlayingTTS = true;
-        if (voiceChat) voiceChat.pauseRecording();
-    },
-    () => {
-        // TTS结束播放回调
-        global.isPlayingTTS = false;
-        if (voiceChat) voiceChat.resumeRecording();
-        // TTS播放结束后，更新自动对话最后交互时间
-        if (global.autoChatModule) {
-            global.autoChatModule.updateLastInteractionTime();
-        }
-        // TTS播放结束后，检查并处理队列中的弹幕
-        processBarrageQueue();
-    },
-    config  // 传递配置对象
-);
-
-// 初始化时增强系统提示词
-function enhanceSystemPrompt() {
-    if (voiceChat && voiceChat.messages && voiceChat.messages.length > 0 && voiceChat.messages[0].role === 'system') {
-        const originalPrompt = voiceChat.messages[0].content;
-
-        // 检查是否已经添加了直播相关提示
-        if (!originalPrompt.includes('你可能会收到直播弹幕')) {
-            const enhancedPrompt = originalPrompt + "\n\n你可能会收到直播弹幕消息，这些消息会被标记为[弹幕]，表示这是来自直播间观众的消息，而不是主人直接对你说的话。当你看到[弹幕]标记时，你应该知道这是其他人发送的，但你仍然可以回应，就像在直播间与观众互动一样。";
-            voiceChat.messages[0].content = enhancedPrompt;
-            console.log('系统提示已增强，添加了直播弹幕相关说明');
-            logToTerminal('info', '系统提示已增强，添加了直播弹幕相关说明');
-        }
-    }
-}
-
-// 将弹幕添加到队列
-function addToBarrageQueue(nickname, text) {
-    barrageQueue.push({ nickname, text });
-    console.log(`弹幕已加入队列: ${nickname}: ${text}`);
-    logToTerminal('info', `弹幕已加入队列: ${nickname}: ${text}`);
-
-    // 如果当前没有TTS播放，尝试处理队列
-    if (!global.isPlayingTTS && !global.isProcessingBarrage) {
-        processBarrageQueue();
-    }
-}
-
-// 处理弹幕队列
-async function processBarrageQueue() {
-    // 如果正在处理弹幕或正在播放TTS，则不处理
-    if (global.isProcessingBarrage || global.isPlayingTTS || barrageQueue.length === 0) {
-        return;
-    }
-
-    global.isProcessingBarrage = true;
-
-    try {
-        // 获取队列中的第一条弹幕
-        const { nickname, text } = barrageQueue.shift();
-        console.log(`处理队列中的弹幕: ${nickname}: ${text}`);
-        logToTerminal('info', `处理队列中的弹幕: ${nickname}: ${text}`);
-
-        // 处理弹幕消息
-        await handleBarrageMessage(nickname, text);
-
-        // 处理完成后，检查队列中是否还有其他弹幕
-        global.isProcessingBarrage = false;
-
-        // 更新自动对话最后交互时间
-        if (global.autoChatModule) {
-            global.autoChatModule.updateLastInteractionTime();
-        }
-
-        // 延迟一下再继续处理，避免连续处理过多弹幕
-        setTimeout(() => {
-            processBarrageQueue();
-        }, 500);
-    } catch (error) {
-        console.error('处理弹幕队列出错:', error);
-        logToTerminal('error', `处理弹幕队列出错: ${error.message}`);
-        global.isProcessingBarrage = false;
-    }
-}
-
-// 处理弹幕消息 - 按顺序执行流程
-async function handleBarrageMessage(nickname, text) {
-    try {
-        if (!voiceChat) return;
-
-        // 如果正在播放TTS，直接返回，不处理弹幕
-        if (global.isPlayingTTS) {
-            console.log('TTS正在播放，弹幕处理已延迟');
-            logToTerminal('info', 'TTS正在播放，弹幕处理已延迟');
-            return;
-        }
-
-        // 确保系统提示已增强
-        enhanceSystemPrompt();
-
-        // 1. 用户输入阶段 - 将弹幕消息添加到主对话历史中，带标记
-        voiceChat.messages.push({
-            'role': 'user',
-            'content': `[弹幕] ${nickname}: ${text}`
-        });
-
-        // 如果启用了上下文限制，需要裁剪消息
-        if (voiceChat.enableContextLimit) {
-            voiceChat.trimMessages();
-        }
-
-        // 2. 准备API请求
-        const requestBody = {
-            model: voiceChat.MODEL,
-            messages: voiceChat.messages,
-            stream: false  // 改为非流式请求，确保完整分析
-        };
-
-        // 添加工具列表（如果可用）
-        if (global.mcpClientModule && global.mcpClientModule.isConnected) {
-            const tools = global.mcpClientModule.getToolsForLLM();
-            if (tools && tools.length > 0) {
-                requestBody.tools = tools;
-            }
-        }
-
-        // 3. 分析阶段 - 发送请求到LLM进行分析
-        const response = await fetch(`${voiceChat.API_URL}/chat/completions`, {
-            method: 'POST',
-            headers: {
-                'Content-Type': 'application/json',
-                'Authorization': `Bearer ${voiceChat.API_KEY}`
-            },
-            body: JSON.stringify(requestBody)
-        });
-
-        if (!response.ok) {
-            // 尝试读取响应体获取详细错误信息
-            let errorDetail = "";
-            try {
-                const errorBody = await response.text();
-                try {
-                    // 尝试解析JSON
-                    const errorJson = JSON.parse(errorBody);
-                    errorDetail = JSON.stringify(errorJson, null, 2);
-                } catch (e) {
-                    errorDetail = errorBody;
-                }
-            } catch (e) {
-                errorDetail = "无法读取错误详情";
-            }
-
-            // 记录完整错误到终端
-            logToTerminal('error', `API错误 (${response.status} ${response.statusText}):\n${errorDetail}`);
-
-            // 根据HTTP状态码提供具体错误信息
-            let errorMessage = "";
-            switch(response.status) {
-                case 401:
-                    errorMessage = "API密钥验证失败，请检查你的API密钥";
-                    break;
-                case 403:
-                    errorMessage = "API访问被禁止，你的账号可能被限制";
-                    break;
-                case 404:
-                    errorMessage = "API接口未找到，请检查API地址";
-                    break;
-                case 429:
-                    errorMessage = "请求过于频繁，超出API限制";
-                    break;
-                case 500:
-                case 502:
-                case 503:
-                case 504:
-                    errorMessage = "服务器错误，AI服务当前不可用";
-                    break;
-                default:
-                    errorMessage = `API错误: ${response.status} ${response.statusText}`;
-            }
-            throw new Error(`${errorMessage}\n详细信息: ${errorDetail}`);
-        }
-
-        // 解析LLM响应
-        const responseData = await response.json();
-        const result = responseData.choices[0].message;
-
-        // 4. 工具调用阶段（如需）- 检查是否需要工具调用
-        if (result.tool_calls && result.tool_calls.length > 0 && global.mcpClientModule) {
-            console.log("检测到工具调用:", result.tool_calls);
-            logToTerminal('info', `检测到工具调用: ${JSON.stringify(result.tool_calls)}`);
-
-            // 将工具调用添加到消息历史
-            voiceChat.messages.push({
-                'role': 'assistant',
-                'content': null,
-                'tool_calls': result.tool_calls
-            });
-
-            // 执行工具调用
-            const toolResult = await global.mcpClientModule.handleToolCalls(result.tool_calls);
-
-            if (toolResult) {
-                console.log("工具调用结果:", toolResult);
-                logToTerminal('info', `工具调用结果: ${toolResult}`);
-
-                // 将工具结果添加到消息历史
-                voiceChat.messages.push({
-                    'role': 'tool',
-                    'content': toolResult,
-                    'tool_call_id': result.tool_calls[0].id
-                });
-
-                // 再次调用LLM获取最终回复
-                const finalRequestOptions = {
-                    method: 'POST',
-                    headers: {
-                        'Content-Type': 'application/json',
-                        'Authorization': `Bearer ${voiceChat.API_KEY}`
-                    },
-                    body: JSON.stringify({
-                        model: voiceChat.MODEL,
-                        messages: voiceChat.messages,
-                        stream: false
-                    })
-                };
-
-                const finalResponse = await fetch(`${voiceChat.API_URL}/chat/completions`, finalRequestOptions);
-
-                if (!finalResponse.ok) {
-                    // 尝试读取错误详情
-                    let errorDetail = "";
-                    try {
-                        const errorBody = await finalResponse.text();
-                        try {
-                            const errorJson = JSON.parse(errorBody);
-                            errorDetail = JSON.stringify(errorJson, null, 2);
-                        } catch (e) {
-                            errorDetail = errorBody;
-                        }
-                    } catch (e) {
-                        errorDetail = "无法读取错误详情";
-                    }
-
-                    // 记录完整错误
-                    logToTerminal('error', `API错误 (${finalResponse.status} ${finalResponse.statusText}):\n${errorDetail}`);
-
-                    // 根据HTTP状态码提供错误信息
-                    let errorMessage = "";
-                    switch(finalResponse.status) {
-                        case 401:
-                            errorMessage = "API密钥验证失败，请检查你的API密钥";
-                            break;
-                        case 403:
-                            errorMessage = "API访问被禁止，你的账号可能被限制";
-                            break;
-                        case 404:
-                            errorMessage = "API接口未找到，请检查API地址";
-                            break;
-                        case 429:
-                            errorMessage = "请求过于频繁，超出API限制";
-                            break;
-                        case 500:
-                        case 502:
-                        case 503:
-                        case 504:
-                            errorMessage = "服务器错误，AI服务当前不可用";
-                            break;
-                        default:
-                            errorMessage = `API错误: ${finalResponse.status} ${finalResponse.statusText}`;
-                    }
-                    throw new Error(`${errorMessage}\n详细信息: ${errorDetail}`);
-                }
-
-                // 获取最终回复
-                const finalResponseData = await finalResponse.json();
-                const finalResult = finalResponseData.choices[0].message;
-
-                // 保存最终回复
-                if (finalResult.content) {
-                    voiceChat.messages.push({'role': 'assistant', 'content': finalResult.content});
-
-                    // 5. 语音输出阶段 - 播放最终回复
-                    ttsProcessor.reset();
-                    ttsProcessor.processTextToSpeech(finalResult.content);
-                }
-            } else {
-                // 工具调用失败处理
-                console.error("工具调用失败");
-                logToTerminal('error', "工具调用失败");
-                throw new Error("工具调用失败，无法完成功能扩展");
-            }
-        } else if (result.content) {
-            // 不需要工具调用，直接处理LLM响应
-            voiceChat.messages.push({'role': 'assistant', 'content': result.content});
-
-            // 5. 语音输出阶段 - 播放回复
-            ttsProcessor.reset();
-            ttsProcessor.processTextToSpeech(result.content);
-        }
-
-        // 再次裁剪消息
-        if (voiceChat.enableContextLimit) {
-            voiceChat.trimMessages();
-        }
-    } catch (error) {
-        // 详细错误记录到终端
-        logToTerminal('error', `处理弹幕消息出错: ${error.message}`);
-        if (error.stack) {
-            logToTerminal('error', `错误堆栈: ${error.stack}`);
-        }
-
-        // 检查错误类型，显示具体错误信息
-        let errorMessage = "抱歉，处理弹幕出错";
-
-        if (error.message.includes("API密钥验证失败")) {
-            errorMessage = "API密钥错误，请检查配置";
-        } else if (error.message.includes("API访问被禁止")) {
-            errorMessage = "API访问受限，请联系支持";
-        } else if (error.message.includes("API接口未找到")) {
-            errorMessage = "无效的API地址，请检查配置";
-        } else if (error.message.includes("请求过于频繁")) {
-            errorMessage = "请求频率超限，请稍后再试";
-        } else if (error.message.includes("服务器错误")) {
-            errorMessage = "AI服务不可用，请稍后再试";
-        } else if (error.message.includes("工具调用失败")) {
-            errorMessage = "功能扩展调用失败，请重试";
-        } else if (error.name === "TypeError" && error.message.includes("fetch")) {
-            errorMessage = "网络连接失败，请检查网络";
-        } else if (error.name === "SyntaxError") {
-            errorMessage = "解析API响应出错，请重试";
-        } else {
-            // 未识别错误，显示原始错误信息
-            errorMessage = `弹幕处理错误: ${error.message}`;
-        }
-
-        // 用户显示的错误消息也记录到终端
-        logToTerminal('error', `用户显示错误: ${errorMessage}`);
-
-        showSubtitle(errorMessage, 3000);
-        // 出错时解锁ASR
-        voiceChat.asrProcessor.resumeRecording();
-        // 延迟隐藏字幕
-        setTimeout(() => hideSubtitle(), 3000);
-    }
-}
-
-(async function main() {
-    try {
-        // 创建语音聊天接口
-        voiceChat = new VoiceChatInterface(
-            config.asr.vad_url,
-            config.asr.asr_url,
-            ttsProcessor,
-            showSubtitle,
-            hideSubtitle,
-            config  // 传递整个配置对象给VoiceChatInterface
-        );
-        global.voiceChat = voiceChat;
-
-        // 创建PIXI应用
-        const app = new PIXI.Application({
-            view: document.getElementById("canvas"),
-            autoStart: true,
-            transparent: true,
-            width: window.innerWidth * 2,
-            height: window.innerHeight * 2
-        });
-
-        app.stage.position.set(window.innerWidth / 2, window.innerHeight / 2);
-        app.stage.pivot.set(window.innerWidth / 2, window.innerHeight / 2);
-
-        // 加载Live2D模型
-        const model = await PIXI.live2d.Live2DModel.from("2D/Hiyori.model3.json");
-        currentModel = model;
-        app.stage.addChild(model);
-
-        // 初始化模型交互控制器
-        modelController.init(model, app);
-        modelController.setupInitialModelProperties(config.ui.model_scale || 2.3);
-
-        // 创建情绪动作映射器
-        emotionMapper = new EmotionMotionMapper(model);
-
-        // 将情绪映射器传递给TTS处理器，实现同步
-        ttsProcessor.setEmotionMapper(emotionMapper);
-
-        // 设置模型和情绪映射器
-        voiceChat.setModel(model);
-        voiceChat.setEmotionMapper = emotionMapper; // 设置情绪映射器引用
-
-        // 初始化时增强系统提示
-        enhanceSystemPrompt();
-
-        // 初始化MCP客户端模块（如果在配置中启用）
-        if (config.mcp && config.mcp.enabled) {
-            mcpClientModule = new MCPClientModule(config, ttsProcessor, emotionMapper);
-
-            // 异步初始化MCP模块
-            mcpClientModule.initialize().then(success => {
-                if (success) {
-                    console.log('MCP客户端模块初始化成功');
-                    logToTerminal('info', 'MCP客户端模块初始化成功');
-                    global.mcpClientModule = mcpClientModule;
-
-                    // 修改VoiceChat的sendToLLM方法，添加工具调用支持，遵循线性流程
-                    voiceChat.sendToLLM = async function(prompt) {
-                        try {
-                            // 标记正在处理用户输入
-                            global.isProcessingUserInput = true;
-
-                            // 1. 用户输入阶段 - 保存用户消息到上下文
-                            this.messages.push({'role': 'user', 'content': prompt});
-
-                            // 裁剪消息历史
-                            if (this.enableContextLimit) {
-                                this.trimMessages();
-                            }
-
-                            // 准备API请求参数 - 处理多模态输入(如截图)
-                            let messagesForAPI = JSON.parse(JSON.stringify(this.messages));
-                            const needScreenshot = await this.shouldTakeScreenshot(prompt);
-
-                            if (needScreenshot) {
-                                try {
-                                    console.log("需要截图");
-                                    logToTerminal('info', "需要截图");
-                                    const screenshotPath = await this.takeScreenshot();
-                                    const base64Image = await this.imageToBase64(screenshotPath);
-
-                                    // 找到最后一条用户消息替换为多模态消息
-                                    const lastUserMsgIndex = messagesForAPI.findIndex(
-                                        msg => msg.role === 'user' && msg.content === prompt
-                                    );
-
-                                    if (lastUserMsgIndex !== -1) {
-                                        messagesForAPI[lastUserMsgIndex] = {
-                                            'role': 'user',
-                                            'content': [
-                                                {'type': 'text', 'text': prompt},
-                                                {'type': 'image_url', 'image_url': {'url': `data:image/jpeg;base64,${base64Image}`}}
-                                            ]
-                                        };
-                                    }
-                                } catch (error) {
-                                    console.error("截图处理失败:", error);
-                                    logToTerminal('error', `截图处理失败: ${error.message}`);
-                                    throw new Error("截图功能出错，无法处理视觉内容");
-                                }
-                            }
-
-                            // 准备API请求
-                            const requestBody = {
-                                model: this.MODEL,
-                                messages: messagesForAPI,
-                                stream: false  // 改为非流式请求，确保完整分析
-                            };
-
-                            // 添加工具列表（如果可用）
-                            if (global.mcpClientModule && global.mcpClientModule.isConnected) {
-                                const tools = global.mcpClientModule.getToolsForLLM();
-                                if (tools && tools.length > 0) {
-                                    requestBody.tools = tools;
-                                }
-                            }
-
-                            // 2. 分析阶段 - 发送请求到LLM进行分析
-                            logToTerminal('info', `开始发送请求到LLM API: ${this.API_URL}/chat/completions`);
-                            const response = await fetch(`${this.API_URL}/chat/completions`, {
-                                method: 'POST',
-                                headers: {
-                                    'Content-Type': 'application/json',
-                                    'Authorization': `Bearer ${this.API_KEY}`
-                                },
-                                body: JSON.stringify(requestBody)
-                            });
-
-                            if (!response.ok) {
-                                // 尝试读取响应体获取详细错误信息
-                                let errorDetail = "";
-                                try {
-                                    const errorBody = await response.text();
-                                    try {
-                                        // 尝试解析JSON
-                                        const errorJson = JSON.parse(errorBody);
-                                        errorDetail = JSON.stringify(errorJson, null, 2);
-                                    } catch (e) {
-                                        errorDetail = errorBody;
-                                    }
-                                } catch (e) {
-                                    errorDetail = "无法读取错误详情";
-                                }
-
-                                // 记录完整错误到终端
-                                logToTerminal('error', `API错误 (${response.status} ${response.statusText}):\n${errorDetail}`);
-
-                                // 根据HTTP状态码提供具体错误信息
-                                let errorMessage = "";
-                                switch(response.status) {
-                                    case 401:
-                                        errorMessage = "API密钥验证失败，请检查你的API密钥";
-                                        break;
-                                    case 403:
-                                        errorMessage = "API访问被禁止，你的账号可能被限制";
-                                        break;
-                                    case 404:
-                                        errorMessage = "API接口未找到，请检查API地址";
-                                        break;
-                                    case 429:
-                                        errorMessage = "请求过于频繁，超出API限制";
-                                        break;
-                                    case 500:
-                                    case 502:
-                                    case 503:
-                                    case 504:
-                                        errorMessage = "服务器错误，AI服务当前不可用";
-                                        break;
-                                    default:
-                                        errorMessage = `API错误: ${response.status} ${response.statusText}`;
-                                }
-                                throw new Error(`${errorMessage}\n详细信息: ${errorDetail}`);
-                            }
-
-                            // 解析LLM响应
-                            const responseData = await response.json();
-                            const result = responseData.choices[0].message;
-                            logToTerminal('info', `收到LLM API响应`);
-
-                            // 3. 工具调用阶段（如需）- 检查是否需要工具调用
-                            if (result.tool_calls && result.tool_calls.length > 0 && global.mcpClientModule) {
-                                console.log("检测到工具调用:", result.tool_calls);
-                                logToTerminal('info', `检测到工具调用: ${JSON.stringify(result.tool_calls)}`);
-
-                                // 将工具调用添加到消息历史
-                                this.messages.push({
-                                    'role': 'assistant',
-                                    'content': null,
-                                    'tool_calls': result.tool_calls
-                                });
-
-                                // 执行工具调用
-                                logToTerminal('info', `开始执行工具调用`);
-                                const toolResult = await global.mcpClientModule.handleToolCalls(result.tool_calls);
-
-                                if (toolResult) {
-                                    console.log("工具调用结果:", toolResult);
-                                    logToTerminal('info', `工具调用结果: ${toolResult}`);
-
-                                    // 将工具结果添加到消息历史
-                                    this.messages.push({
-                                        'role': 'tool',
-                                        'content': toolResult,
-                                        'tool_call_id': result.tool_calls[0].id
-                                    });
-
-                                    // 再次调用LLM获取最终回复
-                                    logToTerminal('info', `发送工具结果到LLM获取最终回复`);
-                                    const finalRequestOptions = {
-                                        method: 'POST',
-                                        headers: {
-                                            'Content-Type': 'application/json',
-                                            'Authorization': `Bearer ${this.API_KEY}`
-                                        },
-                                        body: JSON.stringify({
-                                            model: this.MODEL,
-                                            messages: this.messages,
-                                            stream: false
-                                        })
-                                    };
-
-                                    const finalResponse = await fetch(`${this.API_URL}/chat/completions`, finalRequestOptions);
-
-                                    if (!finalResponse.ok) {
-                                        // 尝试读取错误详情
-                                        let errorDetail = "";
-                                        try {
-                                            const errorBody = await finalResponse.text();
-                                            try {
-                                                const errorJson = JSON.parse(errorBody);
-                                                errorDetail = JSON.stringify(errorJson, null, 2);
-                                            } catch (e) {
-                                                errorDetail = errorBody;
-                                            }
-                                        } catch (e) {
-                                            errorDetail = "无法读取错误详情";
-                                        }
-
-                                        // 记录完整错误
-                                        logToTerminal('error', `API错误 (${finalResponse.status} ${finalResponse.statusText}):\n${errorDetail}`);
-
-                                        // 根据HTTP状态码提供错误信息
-                                        let errorMessage = "";
-                                        switch(finalResponse.status) {
-                                            case 401:
-                                                errorMessage = "API密钥验证失败，请检查你的API密钥";
-                                                break;
-                                            case 403:
-                                                errorMessage = "API访问被禁止，你的账号可能被限制";
-                                                break;
-                                            case 404:
-                                                errorMessage = "API接口未找到，请检查API地址";
-                                                break;
-                                            case 429:
-                                                errorMessage = "请求过于频繁，超出API限制";
-                                                break;
-                                            case 500:
-                                            case 502:
-                                            case 503:
-                                            case 504:
-                                                errorMessage = "服务器错误，AI服务当前不可用";
-                                                break;
-                                            default:
-                                                errorMessage = `API错误: ${finalResponse.status} ${finalResponse.statusText}`;
-                                        }
-                                        throw new Error(`${errorMessage}\n详细信息: ${errorDetail}`);
-                                    }
-
-                                    // 获取最终回复
-                                    const finalResponseData = await finalResponse.json();
-                                    const finalResult = finalResponseData.choices[0].message;
-                                    logToTerminal('info', `获得最终LLM回复，开始语音输出`);
-
-                                    // 保存最终回复
-                                    if (finalResult.content) {
-                                        this.messages.push({'role': 'assistant', 'content': finalResult.content});
-
-                                        // 4. 语音输出阶段 - 播放最终回复
-                                        this.ttsProcessor.reset();
-                                        this.ttsProcessor.processTextToSpeech(finalResult.content);
-                                    }
-                                } else {
-                                    // 工具调用失败处理
-                                    console.error("工具调用失败");
-                                    logToTerminal('error', "工具调用失败");
-                                    throw new Error("工具调用失败，无法完成功能扩展");
-                                }
-                            } else if (result.content) {
-                                // 不需要工具调用，直接处理LLM响应
-                                this.messages.push({'role': 'assistant', 'content': result.content});
-                                logToTerminal('info', `LLM直接返回回复，开始语音输出`);
-
-                                // 4. 语音输出阶段 - 播放回复
-                                this.ttsProcessor.reset();
-                                this.ttsProcessor.processTextToSpeech(result.content);
-                            }
-
-                            // 再次裁剪消息历史
-                            if (this.enableContextLimit) {
-                                this.trimMessages();
-                            }
-                        } catch (error) {
-                            // 详细错误记录到终端
-                            logToTerminal('error', `LLM处理错误: ${error.message}`);
-                            if (error.stack) {
-                                logToTerminal('error', `错误堆栈: ${error.stack}`);
-                            }
-
-                            // 检查错误类型，显示具体错误信息
-                            let errorMessage = "抱歉，出现了一个错误";
-
-                            if (error.message.includes("API密钥验证失败")) {
-                                errorMessage = "API密钥错误，请检查配置";
-                            } else if (error.message.includes("API访问被禁止")) {
-                                errorMessage = "API访问受限，请联系支持";
-                            } else if (error.message.includes("API接口未找到")) {
-                                errorMessage = "无效的API地址，请检查配置";
-                            } else if (error.message.includes("请求过于频繁")) {
-                                errorMessage = "请求频率超限，请稍后再试";
-                            } else if (error.message.includes("服务器错误")) {
-                                errorMessage = "AI服务不可用，请稍后再试";
-                            } else if (error.message.includes("截图功能出错")) {
-                                errorMessage = "截图失败，无法处理视觉内容";
-                            } else if (error.message.includes("工具调用失败")) {
-                                errorMessage = "功能扩展调用失败，请重试";
-                            } else if (error.name === "TypeError" && error.message.includes("fetch")) {
-                                errorMessage = "网络连接失败，请检查网络和API地址";
-                            } else if (error.name === "SyntaxError") {
-                                errorMessage = "解析API响应出错，请重试";
-                            } else {
-                                // 显示原始错误信息，但截断过长的消息
-                                const shortErrorMsg = error.message.substring(0, 100) +
-                                                   (error.message.length > 100 ? "..." : "");
-                                errorMessage = `未知错误: ${shortErrorMsg}`;
-                            }
-
-                            // 用户显示的错误消息也记录到终端
-                            logToTerminal('error', `用户显示错误: ${errorMessage}`);
-
-                            this.showSubtitle(errorMessage, 3000);
-                            // 出错时也要解锁ASR
-                            this.asrProcessor.resumeRecording();
-                            // 出错时也要隐藏字幕
-                            setTimeout(() => this.hideSubtitle(), 3000);
-                        } finally {
-                            // 确保解除处理用户输入的锁定状态
-                            global.isProcessingUserInput = false;
-                        }
-                    };
-                } else {
-                    console.log('MCP客户端模块初始化失败');
-                    logToTerminal('error', 'MCP客户端模块初始化失败');
-                }
-            });
-        }
-
-        // 初始化直播模块（如果在配置中启用）
-        if (config.bilibili && config.bilibili.enabled) {
-            liveStreamModule = new LiveStreamModule({
-                roomId: config.bilibili.roomId || '30230160',
-                checkInterval: config.bilibili.checkInterval || 5000,
-                maxMessages: config.bilibili.maxMessages || 50,
-                apiUrl: config.bilibili.apiUrl || 'http://api.live.bilibili.com/ajax/msg',
-
-                // 处理新弹幕消息
-                onNewMessage: (message) => {
-                    console.log(`收到弹幕: ${message.nickname}: ${message.text}`);
-                    logToTerminal('info', `收到弹幕: ${message.nickname}: ${message.text}`);
-
-                    // 将弹幕添加到处理队列
-                    addToBarrageQueue(message.nickname, message.text);
-                }
-            });
-
-            // 启动直播模块
-            liveStreamModule.start();
-            console.log('直播模块已启动，监听房间:', liveStreamModule.roomId);
-            logToTerminal('info', `直播模块已启动，监听房间: ${liveStreamModule.roomId}`);
-        }
-
-        // 播放欢迎语
-        setTimeout(() => {
-            ttsProcessor.processTextToSpeech(INTRO_TEXT);
-        }, 1000);
-
-        // 开始录音
-        setTimeout(() => {
-            voiceChat.startRecording();
-        }, 3000);
-
-        // 初始化并启动自动对话模块（延迟启动，避免与欢迎语冲突）
-        setTimeout(() => {
-            // 创建自动对话模块实例
-            autoChatModule = new AutoChatModule(config, ttsProcessor);
-
-            // 添加到全局对象，便于其他模块访问
-            global.autoChatModule = autoChatModule;
-
-            // 启动自动对话模块
-            autoChatModule.start();
-            console.log('自动对话模块初始化完成');
-            logToTerminal('info', '自动对话模块初始化完成');
-        }, 8000); // 8秒后初始化自动对话
-
-        // 在main函数中添加（放在voiceChat初始化之后）
-        const chatInput = document.getElementById('chat-input');
-        const chatSendBtn = document.getElementById('chat-send-btn');
-        const textChatContainer = document.getElementById('text-chat-container');
-
-        // 根据配置设置对话框初始显示状态
-        if (config.ui && config.ui.hasOwnProperty('show_chat_box')) {
-            textChatContainer.style.display = config.ui.show_chat_box ? 'block' : 'none';
-        } else {
-            // 如果配置中没有这个选项，默认隐藏
-            textChatContainer.style.display = 'none';
-        }
-
-        // 切换文本框显示/隐藏的快捷键
-        document.addEventListener('keydown', (e) => {
-            if (e.key === 'Alt') {
-                e.preventDefault(); // 防止 Alt 键触发浏览器菜单
-                const chatContainer = document.getElementById('text-chat-container');
-                chatContainer.style.display = chatContainer.style.display === 'none' ? 'block' : 'none';
-            }
-        });
-
-        // 按Enter键发送消息
-        chatInput.addEventListener('keypress', (e) => {
-            if (e.key === 'Enter') {
-                const message = chatInput.value.trim();
-                if (message) {
-                    voiceChat.handleTextMessage(message);
-                    chatInput.value = '';
-                }
-            }
-        });
-
-        // 在模型初始化部分添加：
-        model.hitTest = function(x, y) {
-            return x >= interactionX &&
-                x <= interactionX + interactionWidth &&
-                y >= interactionY &&
-                y <= interactionY + interactionHeight;
-        };
-
-        logToTerminal('info', '应用初始化完成');
-    } catch (error) {
-        console.error("加载模型错误:", error);
-        console.error("错误详情:", error.message);
-        logToTerminal('error', `加载模型错误: ${error.message}`);
-        if (error.stack) {
-            logToTerminal('error', `错误堆栈: ${error.stack}`);
-        }
-    }
-})();
-
-// 清理资源
-window.onbeforeunload = () => {
-    if (voiceChat) {
-        voiceChat.stopRecording();
-    }
-
-    // 停止直播模块
-    if (liveStreamModule && liveStreamModule.isRunning) {
-        liveStreamModule.stop();
-    }
-
-    // 停止自动对话模块
-    if (autoChatModule && autoChatModule.isRunning) {
-        autoChatModule.stop();
-    }
-
-    // 停止MCP客户端模块
-    if (mcpClientModule) {
-        mcpClientModule.stop();
-    }
-
-    logToTerminal('info', '应用已关闭，资源已清理');
-};
\ No newline at end of file
diff --git a/live-2d/css/styles.css b/live-2d/css/styles.css
deleted file mode 100644
index 2fff43e..0000000
--- a/live-2d/css/styles.css
+++ /dev/null
@@ -1,97 +0,0 @@
-body {
-    margin: 0;
-    padding: 0;
-    background: transparent;
-    overflow: hidden;
-    user-select: none;
-    -webkit-user-select: none;
-}
-
-#canvas {
-    position: fixed;
-    top: 0;
-    left: 0;
-    width: 100%;
-    height: 100%;
-}
-
-#subtitle-container {
-    position: fixed;
-    bottom: 20px;
-    left: 70%;
-    transform: translateX(-50%);
-    max-width: 80%;
-    max-height: 300px;
-    padding: 10px 20px;
-    border-radius: 10px;
-    z-index: 1000;
-    display: none;
-    text-align: center;
-    overflow-y: hidden; /* 可能的丢包问题 */
-    word-wrap: break-word;
-    white-space: pre-wrap;
-    scrollbar-width: none;
-    -ms-overflow-style: none;
-}
-
-#subtitle-text {
-    color: white;
-    font-size: 30px;
-    margin: 0;
-    font-family: 'Patrick Hand', 'ZCOOL QingKe HuangYou', sans-serif;
-    line-height: 1.5;
-    font-weight: 900;
-    text-shadow: 
-          -0.5px -0.5px 0 black,
-          0.5px -0.5px 0 black,
-          -0.5px 0.5px 0 black,
-          1.5px 1.5px 0 black;
-}
-
-#text-chat-container {
-    position: fixed;
-    bottom: 20px;
-    right: 20px; /* 已修改：从left改为right */
-    width: 300px;
-    max-height: 400px;
-    background-color: rgba(0, 0, 0, 0.7);
-    border-radius: 10px;
-    padding: 10px;
-    z-index: 1000;
-    display: none;
-    pointer-events: auto; /* 确保鼠标事件能正常触发 */
-}
-
-#chat-messages {
-    display: none; /* 隐藏消息记录区域 */
-    max-height: 300px;
-    overflow-y: auto;
-    margin-bottom: 10px;
-    color: white;
-    font-family: 'Patrick Hand', sans-serif;
-}
-
-#chat-input-container {
-    display: flex;
-    gap: 5px;
-}
-
-#chat-input {
-    flex: 1;
-    padding: 5px;
-    border-radius: 5px;
-    border: none;
-}
-
-#chat-send-btn {
-    padding: 5px 10px;
-    border-radius: 5px;
-    border: none;
-    background-color: #4CAF50;
-    color: white;
-    cursor: pointer;
-}
-
-#chat-send-btn:hover {
-    background-color: #45a049;
-}
\ No newline at end of file
diff --git a/live-2d/go.bat b/live-2d/go.bat
deleted file mode 100644
index 59098b0..0000000
--- a/live-2d/go.bat
+++ /dev/null
@@ -1,6 +0,0 @@
-@echo off
-chcp 65001
-cd /d %~dp0
-echo 正在启动桌宠应用...
-.\node\node.exe .\node_modules\electron\cli.js .
-pause
\ No newline at end of file
diff --git a/live-2d/index.html b/live-2d/index.html
deleted file mode 100644
index f3f1e05..0000000
--- a/live-2d/index.html
+++ /dev/null
@@ -1,32 +0,0 @@
-<!DOCTYPE html>
-<html>
-<head>
-    <link href="https://fonts.googleapis.com/css2?family=Patrick+Hand&display=swap" rel="stylesheet">
-    <link rel="stylesheet" href="css/styles.css">
-    <title>Live2D桌宠与语音聊天</title>
-</head>
-<body>
-    <canvas id="canvas"></canvas>
-    <div id="subtitle-container">
-        <p id="subtitle-text"></p>
-    </div>
-
-    <div id="text-chat-container">
-        <div id="chat-messages"></div>
-        <div id="chat-input-container">
-            <input type="text" id="chat-input" placeholder="输入消息...">
-            <!-- <button id="chat-send-btn">发送</button> -->
-        </div>
-    </div>
-    
-    <!-- 使用本地库文件替代CDN -->
-    <script src="libs/live2dcubismcore.min.js"></script>
-    <script src="libs/live2d.min.js"></script>
-    <script src="libs/pixi.min.js"></script>
-    <script src="libs/pixi-live2d-display.min.js"></script>
-    <script src="libs/pixi-live2d-display-extra.min.js"></script>
-    <script src="app.js"></script>
-
-        
-</body>
-</html>
\ No newline at end of file
diff --git a/live-2d/js/LiveStreamModule.js b/live-2d/js/LiveStreamModule.js
deleted file mode 100644
index a8d2444..0000000
--- a/live-2d/js/LiveStreamModule.js
+++ /dev/null
@@ -1,151 +0,0 @@
-class LiveStreamModule {
-    constructor(config) {
-        // 配置参数
-        this.roomId = config.roomId || '30230160'; // 默认房间ID
-        this.checkInterval = config.checkInterval || 5000; // 轮询间隔，默认5秒
-        this.maxMessages = config.maxMessages || 50; // 最大缓存消息数
-        this.apiUrl = config.apiUrl || 'http://api.live.bilibili.com/ajax/msg'; // 弹幕API地址
-        this.onNewMessage = config.onNewMessage || null; // 新消息回调函数
-        
-        // 状态变量
-        this.lastCheckedTimestamp = Date.now() / 1000; // 上次检查的时间戳
-        this.isRunning = false; // 模块是否运行中
-        this.checkTimer = null; // 轮询定时器
-        this.messageCache = []; // 消息缓存
-    }
-
-    // 启动直播模块
-    start() {
-        if (this.isRunning) return false;
-        
-        this.isRunning = true;
-        this.fetchBarrage(); // 立即获取一次
-        
-        // 设置定时获取
-        this.checkTimer = setInterval(() => {
-            this.fetchBarrage();
-        }, this.checkInterval);
-        
-        console.log(`直播模块已启动，监听房间: ${this.roomId}`);
-        return true;
-    }
-
-    // 停止直播模块
-    stop() {
-        if (!this.isRunning) return false;
-        
-        clearInterval(this.checkTimer);
-        this.checkTimer = null;
-        this.isRunning = false;
-        
-        console.log('直播模块已停止');
-        return true;
-    }
-
-    // 获取弹幕
-    async fetchBarrage() {
-        try {
-            // 构建API请求URL
-            const url = `${this.apiUrl}?roomid=${this.roomId}`;
-            
-            const response = await fetch(url, {
-                headers: {
-                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'
-                }
-            });
-
-            if (!response.ok) {
-                throw new Error(`获取弹幕失败：HTTP状态码 ${response.status}`);
-            }
-            
-            const data = await response.json();
-            
-            if (!data || !data.data || !data.data.room) {
-                throw new Error('API返回数据格式错误');
-            }
-            
-            const messages = data.data.room;
-            
-            // 过滤出新消息
-            const newMessages = messages.filter(message => {
-                const messageTime = new Date(message.timeline).getTime() / 1000;
-                return messageTime > this.lastCheckedTimestamp;
-            });
-            
-            // 只有在有新消息时更新时间戳
-            if (newMessages.length > 0) {
-                this.lastCheckedTimestamp = Date.now() / 1000;
-                
-                // 更新消息缓存
-                this.messageCache = [...this.messageCache, ...newMessages];
-                
-                // 如果超过最大缓存数量，裁剪旧消息
-                if (this.messageCache.length > this.maxMessages) {
-                    this.messageCache = this.messageCache.slice(-this.maxMessages);
-                }
-                
-                // 处理每条新消息
-                for (const message of newMessages) {
-                    if (this.onNewMessage) {
-                        this.onNewMessage(message);
-                    }
-                }
-            }
-        } catch (error) {
-            console.error('获取弹幕出错:', error);
-        }
-    }
-
-    // 获取缓存的所有消息
-    getMessages() {
-        return [...this.messageCache];
-    }
-
-    // 清除消息缓存
-    clearMessages() {
-        this.messageCache = [];
-    }
-
-    // 修改房间ID
-    setRoomId(roomId) {
-        if (!roomId) return false;
-        
-        this.roomId = roomId;
-        
-        // 如果正在运行，重启以应用新的房间ID
-        if (this.isRunning) {
-            this.stop();
-            this.start();
-        }
-        
-        return true;
-    }
-
-    // 修改轮询间隔
-    setCheckInterval(interval) {
-        if (!interval || interval < 1000) return false; // 至少1秒
-        
-        this.checkInterval = interval;
-        
-        // 如果正在运行，重启以应用新的轮询间隔
-        if (this.isRunning) {
-            this.stop();
-            this.start();
-        }
-        
-        return true;
-    }
-
-    // 获取模块当前状态
-    getStatus() {
-        return {
-            isRunning: this.isRunning,
-            roomId: this.roomId,
-            checkInterval: this.checkInterval,
-            lastCheckedTimestamp: this.lastCheckedTimestamp,
-            messageCount: this.messageCache.length
-        };
-    }
-}
-
-module.exports = { LiveStreamModule };
\ No newline at end of file
diff --git a/live-2d/js/asr-processor.js b/live-2d/js/asr-processor.js
deleted file mode 100644
index 6004ccc..0000000
--- a/live-2d/js/asr-processor.js
+++ /dev/null
@@ -1,316 +0,0 @@
-// ASR（自动语音识别）功能模块
-class ASRProcessor {
-    constructor(vadUrl, asrUrl) {
-        this.vadUrl = vadUrl;
-        this.asrUrl = asrUrl;
-        this.isProcessingAudio = false;
-        this.asrLocked = false;
-        
-        // 音频相关参数
-        this.audioContext = null;
-        this.mediaStream = null;
-        this.ws = null;
-        this.SAMPLE_RATE = 16000;
-        this.WINDOW_SIZE = 512;
-        this.retryCount = 0;
-        this.MAX_RETRIES = 5;
-
-        // 缓冲区设置
-        this.audioBuffer = [];
-        this.BUFFER_DURATION = 1000;
-        this.BUFFER_SIZE = Math.floor(this.SAMPLE_RATE * (this.BUFFER_DURATION / 1000));
-        
-        // 录音相关
-        this.isRecording = false;
-        this.continuousBuffer = [];
-        this.recordingStartIndex = 0;
-        this.PRE_RECORD_TIME = 1;
-        this.PRE_RECORD_SAMPLES = this.SAMPLE_RATE * this.PRE_RECORD_TIME;
-        
-        // 静音检测
-        this.lastSpeechTime = 0;
-        this.SILENCE_THRESHOLD = 500;
-        this.silenceTimeout = null;
-
-        // 初始化
-        this.setupAudioSystem();
-    }
-
-    async setupAudioSystem() {
-        try {
-            await this.setupWebSocket();
-        } catch (error) {
-            console.error('音频系统设置错误:', error);
-        }
-    }
-
-    async setupWebSocket() {
-        if (this.ws && this.ws.readyState === WebSocket.OPEN) {
-            this.ws.close();
-        }
-        
-        this.ws = new WebSocket(this.vadUrl);
-
-        this.ws.onopen = async () => {
-            console.log('VAD WebSocket已连接');
-            this.retryCount = 0;
-        };
-
-        this.ws.onmessage = (event) => {
-            // 如果锁定则忽略所有语音输入
-            if (this.isProcessingAudio || this.asrLocked) return; 
-            
-            const data = JSON.parse(event.data);
-            const isSpeaking = data.is_speech;
-
-            if (isSpeaking) {
-                this.handleSpeech();
-            } else {
-                this.handleSilence();
-            }
-        };
-
-        this.ws.onclose = () => {
-            console.log('VAD WebSocket已断开');
-            if (this.retryCount < this.MAX_RETRIES) {
-                this.retryCount++;
-                console.log(`尝试重新连接... (${this.retryCount}/${this.MAX_RETRIES})`);
-                setTimeout(() => this.setupWebSocket(), 1000);
-            }
-        };
-
-        this.ws.onerror = (error) => {
-            console.error('WebSocket错误:', error);
-        };
-    }
-
-    handleSpeech() {
-        // 检查ASR是否锁定，如果锁定则不处理语音
-        if (this.isProcessingAudio || this.asrLocked) return; 
-        
-        // 立即设置全局状态为正在处理用户输入，防止自动对话触发
-        global.isProcessingUserInput = true;
-        
-        this.lastSpeechTime = Date.now();
-        
-        if (this.silenceTimeout) {
-            clearTimeout(this.silenceTimeout);
-            this.silenceTimeout = null;
-        }
-
-        if (!this.isRecording) {
-            this.isRecording = true;
-            this.recordingStartIndex = this.continuousBuffer.length;
-        }
-    }
-
-    handleSilence() {
-        // 检查ASR是否锁定，如果锁定则不处理语音
-        if (this.isProcessingAudio || this.asrLocked) return; 
-        
-        if (this.isRecording) {
-            const currentTime = Date.now();
-            const silenceDuration = currentTime - this.lastSpeechTime;
-            
-            if (!this.silenceTimeout) {
-                this.silenceTimeout = setTimeout(() => {
-                    this.finishRecording();
-                    this.silenceTimeout = null;
-                }, this.SILENCE_THRESHOLD);
-            }
-        } else {
-            // 如果不是在录音状态，重置用户输入处理标志
-            global.isProcessingUserInput = false;
-        }
-    }
-
-    async startRecording() {
-        try {
-            this.mediaStream = await navigator.mediaDevices.getUserMedia({ 
-                audio: {
-                    channelCount: 1,
-                    sampleRate: this.SAMPLE_RATE,
-                    echoCancellation: true,
-                    noiseSuppression: true
-                } 
-            });
-
-            this.audioContext = new AudioContext({ sampleRate: this.SAMPLE_RATE });
-            const microphone = this.audioContext.createMediaStreamSource(this.mediaStream);
-            const scriptNode = this.audioContext.createScriptProcessor(this.WINDOW_SIZE, 1, 1);
-
-            microphone.connect(scriptNode);
-            scriptNode.connect(this.audioContext.destination);
-
-            let lastSendTime = 0;
-            const MIN_SEND_INTERVAL = 1;
-
-            scriptNode.onaudioprocess = (e) => {
-                // 检查ASR是否锁定，如果锁定则跳过音频处理
-                if (this.isProcessingAudio || this.asrLocked) return; 
-                
-                const currentTime = Date.now();
-                const audioData = e.inputBuffer.getChannelData(0);
-                
-                this.continuousBuffer.push(...Array.from(audioData));
-                
-                if (this.continuousBuffer.length > this.SAMPLE_RATE * 30) {
-                    const excessSamples = this.continuousBuffer.length - this.SAMPLE_RATE * 30;
-                    this.continuousBuffer = this.continuousBuffer.slice(excessSamples);
-                    if (this.isRecording) {
-                        this.recordingStartIndex = Math.max(0, this.recordingStartIndex - excessSamples);
-                    }
-                }
-                
-                if (this.ws && this.ws.readyState === WebSocket.OPEN && 
-                    currentTime - lastSendTime >= MIN_SEND_INTERVAL) {
-                    this.ws.send(audioData);
-                    lastSendTime = currentTime;
-                }
-            };
-
-            console.log('音频处理已启动');
-        } catch (err) {
-            console.error('启动音频错误:', err);
-        }
-    }
-
-    stopRecording() {
-        if (this.mediaStream) {
-            this.mediaStream.getTracks().forEach(track => track.stop());
-        }
-        if (this.ws) {
-            this.ws.close();
-        }
-        if (this.silenceTimeout) {
-            clearTimeout(this.silenceTimeout);
-        }
-    }
-
-    async finishRecording() {
-        // 检查ASR是否锁定，如果锁定则不处理录音
-        if (!this.isRecording || this.isProcessingAudio || this.asrLocked) return;
-        this.isRecording = false;
-        
-        // 在开始处理录音时立即锁定ASR，防止二次接收
-        this.asrLocked = true;
-        console.log('ASR锁定：开始处理录音');
-        
-        const recordingEndIndex = this.continuousBuffer.length;
-        const actualStartIndex = Math.max(0, this.recordingStartIndex - this.PRE_RECORD_SAMPLES);
-        const recordedSamples = this.continuousBuffer.slice(actualStartIndex, recordingEndIndex);
-        
-        if (recordedSamples.length > this.SAMPLE_RATE * 0.5) {
-            const wavBlob = this.float32ToWav(new Float32Array(recordedSamples));
-            await this.processRecording(wavBlob);
-        } else {
-            console.log("录音太短，丢弃");
-            // 即使丢弃录音也保持锁定，直到交互完成
-            this.asrLocked = false;
-            // 重置全局处理状态
-            global.isProcessingUserInput = false;
-        }
-        
-        this.continuousBuffer = this.continuousBuffer.slice(-this.PRE_RECORD_SAMPLES);
-    }
-
-    float32ToWav(samples) {
-        const buffer = new ArrayBuffer(44 + samples.length * 2);
-        const view = new DataView(buffer);
-        
-        this.writeString(view, 0, 'RIFF');
-        view.setUint32(4, 36 + samples.length * 2, true);
-        this.writeString(view, 8, 'WAVE');
-        this.writeString(view, 12, 'fmt ');
-        view.setUint32(16, 16, true);
-        view.setUint16(20, 1, true);
-        view.setUint16(22, 1, true);
-        view.setUint32(24, this.SAMPLE_RATE, true);
-        view.setUint32(28, this.SAMPLE_RATE * 2, true);
-        view.setUint16(32, 2, true);
-        view.setUint16(34, 16, true);
-        this.writeString(view, 36, 'data');
-        view.setUint32(40, samples.length * 2, true);
-
-        this.floatTo16BitPCM(view, 44, samples);
-
-        return new Blob([buffer], { type: 'audio/wav' });
-    }
-
-    writeString(view, offset, string) {
-        for (let i = 0; i < string.length; i++) {
-            view.setUint8(offset + i, string.charCodeAt(i));
-        }
-    }
-
-    floatTo16BitPCM(view, offset, input) {
-        for (let i = 0; i < input.length; i++, offset += 2) {
-            const s = Math.max(-1, Math.min(1, input[i]));
-            view.setInt16(offset, s < 0 ? s * 0x8000 : s * 0x7FFF, true);
-        }
-    }
-
-    async processRecording(audioBlob) {
-        const formData = new FormData();
-        formData.append('file', audioBlob, 'recording.wav');
-        
-        try {
-            const response = await fetch(this.asrUrl, {
-                method: 'POST',
-                body: formData
-            });
-
-            const result = await response.json();
-            if (result.status === 'success' && result.text) {
-                console.log("用户说:", result.text);
-                
-                // 回调函数，由外部实现
-                if (this.onSpeechRecognized) {
-                    this.onSpeechRecognized(result.text);
-                }
-                
-                return result.text;
-            } else {
-                console.error('ASR失败:', result.message);
-                // 如果ASR失败，也要解锁ASR以允许用户重试
-                this.asrLocked = false;
-                // 重置全局处理状态
-                global.isProcessingUserInput = false;
-                return null;
-            }
-        } catch (error) {
-            console.error('处理录音失败:', error);
-            // 如果处理失败，也要解锁ASR以允许用户重试
-            this.asrLocked = false;
-            // 重置全局处理状态
-            global.isProcessingUserInput = false;
-            return null;
-        }
-    }
-
-    pauseRecording() {
-        if (this.mediaStream) {
-            this.mediaStream.getTracks().forEach(track => track.enabled = false);
-        }
-        this.isProcessingAudio = true;
-        console.log('Recording paused');
-    }
-
-    resumeRecording() {
-        if (this.mediaStream) {
-            this.mediaStream.getTracks().forEach(track => track.enabled = true);
-        }
-        this.isProcessingAudio = false;
-        
-        // 解锁ASR，只有当整个对话流程完成后才解锁
-        this.asrLocked = false;
-        console.log('Recording resumed, ASR unlocked');
-    }
-
-    // 设置语音识别完成的回调函数
-    setOnSpeechRecognized(callback) {
-        this.onSpeechRecognized = callback;
-    }
-}
-
-module.exports = { ASRProcessor };
\ No newline at end of file
diff --git a/live-2d/js/config-loader.js b/live-2d/js/config-loader.js
deleted file mode 100644
index 6358d49..0000000
--- a/live-2d/js/config-loader.js
+++ /dev/null
@@ -1,73 +0,0 @@
-const fs = require('fs');
-const path = require('path');
-const os = require('os');
-
-class ConfigLoader {
-    constructor() {
-        this.config = null;
-        this.configPath = path.join(__dirname, '..', 'config.json');
-        this.defaultConfigPath = path.join(__dirname, '..', 'default_config.json');
-    }
-
-    // 修改后的加载配置文件方法，如果格式不对就直接报错
-    load() {
-        try {
-            // 直接读取配置文件
-            const configData = fs.readFileSync(this.configPath, 'utf8');
-            
-            try {
-                // 尝试解析 JSON
-                this.config = JSON.parse(configData);
-            } catch (parseError) {
-                // JSON 解析失败，说明格式不对
-                throw new Error(`JSON格式错误: ${parseError.message}`);
-            }
-            
-            console.log('配置文件加载成功');
-            
-            // 处理特殊路径，例如 ~ 表示用户主目录
-            this.processSpecialPaths();
-            
-            return this.config;
-        } catch (error) {
-            console.error('配置文件读取失败:', error);
-            throw error; // 直接抛出错误，不提供默认配置
-        }
-    }
-    
-    // 处理特殊路径，比如将 ~ 展开为用户主目录
-    processSpecialPaths() {
-        if (this.config.vision && this.config.vision.screenshot_path) {
-            this.config.vision.screenshot_path = this.config.vision.screenshot_path.replace(/^~/, os.homedir());
-        }
-    }
-
-    // 保存配置
-    save(config = null) {
-        try {
-            const configToSave = config || this.config;
-            if (!configToSave) {
-                throw new Error('没有可保存的配置');
-            }
-            
-            // 创建配置文件备份
-            if (fs.existsSync(this.configPath)) {
-                const backupPath = `${this.configPath}.bak`;
-                fs.copyFileSync(this.configPath, backupPath);
-                console.log(`已创建配置文件备份: ${backupPath}`);
-            }
-            
-            // 保存配置
-            fs.writeFileSync(this.configPath, JSON.stringify(configToSave, null, 2), 'utf8');
-            console.log('配置已保存');
-            return true;
-        } catch (error) {
-            console.error('保存配置失败:', error);
-            return false;
-        }
-    }
-}
-
-// 创建并导出单例
-const configLoader = new ConfigLoader();
-module.exports = { configLoader };
\ No newline at end of file
diff --git a/live-2d/js/emotion-motion-mapper.js b/live-2d/js/emotion-motion-mapper.js
deleted file mode 100644
index 8fdda34..0000000
--- a/live-2d/js/emotion-motion-mapper.js
+++ /dev/null
@@ -1,199 +0,0 @@
-// synchronized-emotion-motion-mapper.js - 与TTS系统同步的情绪动作映射器
-class EmotionMotionMapper {
-    constructor(model) {
-        this.model = model;
-        this.currentMotionGroup = "TapBody";  // 使用TapBody组，包含所有动作
-        
-        // 情绪到动作索引的映射
-        this.emotionMap = {
-            '开心高': 0,   // 动作0：左右歪头，结尾闭眼笑嘻嘻（打量开心，兴奋度3）
-            '开心低': 1,   // 动作1：双手对称摇动，头左右摇动（开心，兴奋度1）
-            '愧疚': 2,     // 动作2：皱眉，双手放背后，扭捏表情（愧疚情绪）
-            '开心中': 3,   // 动作3：摇晃身体，张开双臂，笑脸（开心，兴奋度2）
-            '俏皮': 4,     // 动作4：手臂抬至胸前，由中间向外展开，结尾笑脸（俏皮，可爱）
-            '惊讶': 5,     // 动作5：双手放到背后，身体一抖，惊愕状（惊讶、困惑）
-            '兴奋': 6,     // 动作6：双手抬至胸前快速展开，结尾笑脸（高兴兴奋）
-            '赌气': 7,     // 动作7：抬眉毛，然后半闭眼赌气（赌气、可爱）
-            '悲伤': 8      // 动作8：双手放置背后，皱眉，难受（悲伤）
-        };
-        
-        // 动作描述，用于日志
-        this.motionDescriptions = [
-            "开心兴奋(0号): 左右歪头，结尾闭眼笑嘻嘻",
-            "轻微开心(1号): 双手对称摇动，头左右摇动",
-            "愧疚(2号): 皱眉，双手放背后，扭捏表情",
-            "中等开心(3号): 摇晃身体，张开双臂，笑脸", 
-            "俏皮可爱(4号): 手臂抬至胸前，由中间向外展开",
-            "惊讶(5号): 双手放到背后，身体一抖，惊愕状",
-            "高度兴奋(6号): 双手抬至胸前，由中间向外展开，更快速",
-            "赌气(7号): 抬眉毛，然后半闭眼赌气",
-            "悲伤(8号): 双手放置背后，皱眉，难受"
-        ];
-        
-        // 动作播放状态
-        this.isPlayingMotion = false;
-        
-        // 动作之间的间隔时间（毫秒）
-        this.motionInterval = 2000; // 默认2秒间隔
-    }
-
-    // 解析文本，提取所有情绪标签和位置信息
-    parseEmotionTagsWithPosition(text) {
-        // 使用正则表达式匹配所有情绪标签 《xxx》
-        const pattern = /<([^>]+)>/g;
-        const emotions = [];
-        let match;
-        
-        while ((match = pattern.exec(text)) !== null) {
-            emotions.push({
-                emotion: match[1],
-                startIndex: match.index,
-                endIndex: match.index + match[0].length,
-                fullTag: match[0]
-            });
-        }
-        
-        return emotions;
-    }
-
-    // 预处理文本，为TTS系统做准备
-    // 返回: { text: 去除情绪标签的纯文本, emotionMarkers: 带位置信息的情绪标记 }
-    prepareTextForTTS(text) {
-        // 提取情绪标签和位置
-        const emotionTags = this.parseEmotionTagsWithPosition(text);
-        
-        // 如果没有情绪标签，直接返回原文本
-        if (emotionTags.length === 0) {
-            return { 
-                text: text, 
-                emotionMarkers: [] 
-            };
-        }
-        
-        // 创建纯文本版本（移除所有情绪标签）
-        let purifiedText = text;
-        // 从后向前处理，避免位置偏移问题
-        for (let i = emotionTags.length - 1; i >= 0; i--) {
-            const tag = emotionTags[i];
-            purifiedText = purifiedText.substring(0, tag.startIndex) + 
-                           purifiedText.substring(tag.endIndex);
-        }
-        
-        // 创建情绪标记数组，转换为基于字符位置的标记
-        const emotionMarkers = [];
-        let offset = 0;
-        
-        for (const tag of emotionTags) {
-            // 计算标签位置，考虑前面移除的标签导致的偏移
-            const adjustedPosition = tag.startIndex - offset;
-            
-            // 标签长度会影响后续标签的位置计算
-            offset += tag.endIndex - tag.startIndex;
-            
-            // 检查情绪是否有效
-            const motionIndex = this.emotionMap[tag.emotion];
-            if (motionIndex !== undefined) {
-                emotionMarkers.push({
-                    position: adjustedPosition,
-                    emotion: tag.emotion,
-                    motionIndex: motionIndex
-                });
-            }
-        }
-        
-        return {
-            text: purifiedText,
-            emotionMarkers: emotionMarkers
-        };
-    }
-    
-    // 根据文字显示位置触发情绪动作
-    // position: 当前字幕显示到的字符位置
-    // textLength: 总字符长度
-    triggerEmotionByTextPosition(position, textLength, emotionMarkers) {
-        if (!emotionMarkers || emotionMarkers.length === 0) return;
-        
-        // 找到当前位置应该触发的情绪
-        for (const marker of emotionMarkers) {
-            // 当字幕位置刚好到达或略微超过情绪标记位置时触发
-            if (position >= marker.position && 
-                position <= marker.position + 2) { // 添加小缓冲区，避免可能的同步误差
-                
-                // 触发对应的动作
-                const motionIndex = marker.motionIndex;
-                console.log(`触发情绪: ${marker.emotion}, 动作: ${motionIndex} - ${this.motionDescriptions[motionIndex]}`);
-                this.playMotion(motionIndex);
-                
-                // 移除已处理的标记，避免重复触发
-                const index = emotionMarkers.indexOf(marker);
-                if (index > -1) {
-                    emotionMarkers.splice(index, 1);
-                }
-                
-                break; // 一次只处理一个情绪标记
-            }
-        }
-    }
-
-    // 为了向后兼容，保留原有接口，但修改内部实现
-    triggerMotionByEmotion(text) {
-        // 提取第一个情绪标签
-        const match = text.match(/<([^>]+)>/);
-        if (match && match[1]) {
-            const emotion = match[1];
-            const motionIndex = this.emotionMap[emotion];
-            
-            if (motionIndex !== undefined) {
-                console.log(`检测到情绪: ${emotion}, 触发动作: ${motionIndex} - ${this.motionDescriptions[motionIndex]}`);
-                this.playMotion(motionIndex);
-            }
-        }
-        
-        // 移除所有情绪标签后返回纯文本
-        return text.replace(/<[^>]+>/g, '').trim();
-    }
-    
-    // 播放指定索引的动作
-    playMotion(index) {
-        if (!this.model) return;
-        
-        try {
-            // 获取动作配置
-            const motionDefinitions = this.model.internalModel.settings.motions[this.currentMotionGroup];
-            if (!motionDefinitions || motionDefinitions.length === 0) {
-                console.error('没有找到动作定义');
-                return;
-            }
-            
-            // 确保索引在有效范围内
-            const motionIndex = index % motionDefinitions.length;
-            
-            // 停止当前动作
-            if (this.model.internalModel && this.model.internalModel.motionManager) {
-                this.model.internalModel.motionManager.stopAllMotions();
-            }
-            
-            // 播放新动作
-            this.model.motion(this.currentMotionGroup, motionIndex);
-            
-            // 获取当前动作文件名称进行打印
-            const currentMotionFile = motionDefinitions[motionIndex].File;
-            console.log(`播放动作: ${currentMotionFile} (索引: ${motionIndex})`);
-        } catch (error) {
-            console.error('播放动作失败:', error);
-        }
-    }
-    
-    // 播放默认动作
-    playDefaultMotion() {
-        // 播放默认的Idle动作
-        try {
-            this.model.motion("Idle", 0);
-            console.log("播放默认动作: Idle");
-        } catch (error) {
-            console.error('播放默认动作失败:', error);
-        }
-    }
-}
-
-module.exports = { EmotionMotionMapper };
\ No newline at end of file
diff --git a/live-2d/js/mcp-client-module.js b/live-2d/js/mcp-client-module.js
deleted file mode 100644
index d3152e8..0000000
--- a/live-2d/js/mcp-client-module.js
+++ /dev/null
@@ -1,168 +0,0 @@
-// MCP客户端模块 - 集成到AI桌宠系统
-class MCPClientModule {
-    constructor(config, ttsProcessor, emotionMapper) {
-        // 保存配置和依赖项
-        this.config = config.mcp || {};
-        this.ttsProcessor = ttsProcessor;
-        this.emotionMapper = emotionMapper;
-        this.isEnabled = this.config.enabled || false;
-        this.serverUrl = this.config.server_url || 'http://localhost:3000';
-        
-        // 状态标志
-        this.isConnected = false;
-        this.availableTools = [];
-        this.sessionId = this.generateSessionId();
-        
-        console.log(`MCP客户端模块已创建，启用状态: ${this.isEnabled}`);
-    }
-    
-    // 初始化模块
-    async initialize() {
-        if (!this.isEnabled) {
-            console.log('MCP功能已禁用，不进行初始化');
-            return false;
-        }
-        
-        console.log('正在初始化MCP客户端模块...');
-        return await this.discoverMCPTools();
-    }
-    
-    // 发现可用的MCP工具
-    async discoverMCPTools() {
-        try {
-            console.log(`尝试连接MCP服务器: ${this.serverUrl}/mcp/v1/discover`);
-            
-            const response = await fetch(`${this.serverUrl}/mcp/v1/discover`, {
-                method: 'POST',
-                headers: {
-                    'Content-Type': 'application/json'
-                },
-                body: JSON.stringify({
-                    session_id: this.sessionId
-                })
-            });
-            
-            if (!response.ok) {
-                throw new Error(`HTTP错误: ${response.status}`);
-            }
-            
-            const data = await response.json();
-            
-            // 保存可用工具列表
-            this.availableTools = data.functions || [];
-            this.serverInfo = data.server || { name: "未知MCP服务器" };
-            this.isConnected = true;
-            
-            console.log(`已连接到MCP服务器: ${this.serverInfo.name}`);
-            console.log(`可用工具(${this.availableTools.length}): ${this.availableTools.map(t => t.name).join(', ')}`);
-            
-            return true;
-        } catch (error) {
-            console.error('MCP服务器连接失败:', error);
-            this.isConnected = false;
-            return false;
-        }
-    }
-    
-    // 获取工具列表，用于传递给LLM
-    getToolsForLLM() {
-        if (!this.isEnabled || !this.isConnected || this.availableTools.length === 0) {
-            return [];
-        }
-        
-        return this.availableTools.map(tool => ({
-            type: "function",
-            function: {
-                name: tool.name,
-                description: tool.description,
-                parameters: tool.parameters
-            }
-        }));
-    }
-    
-    // 处理LLM返回的工具调用
-    async handleToolCalls(toolCalls) {
-        if (!this.isEnabled || !this.isConnected || !toolCalls || toolCalls.length === 0) {
-            return null;
-        }
-        
-        const toolCall = toolCalls[0]; // 处理第一个工具调用
-        const functionName = toolCall.function.name;
-        
-        // 解析参数
-        let parameters;
-        try {
-            parameters = typeof toolCall.function.arguments === 'string'
-                ? JSON.parse(toolCall.function.arguments)
-                : toolCall.function.arguments;
-        } catch (error) {
-            console.error('解析工具参数错误:', error);
-            parameters = {};
-        }
-        
-        // 调用MCP工具
-        return await this.invokeFunction(functionName, parameters);
-    }
-    
-    // 调用MCP工具
-    async invokeFunction(functionName, parameters) {
-        if (!this.isEnabled || !this.isConnected) {
-            console.error('MCP功能未启用或未连接到服务器');
-            return null;
-        }
-        
-        // 查找工具是否存在
-        const tool = this.availableTools.find(t => t.name === functionName);
-        if (!tool) {
-            console.error(`未找到MCP工具: ${functionName}`);
-            return null;
-        }
-        
-        try {
-            console.log(`调用MCP工具: ${functionName}，参数:`, parameters);
-            
-            const response = await fetch(`${this.serverUrl}/mcp/v1/invoke`, {
-                method: 'POST',
-                headers: {
-                    'Content-Type': 'application/json'
-                },
-                body: JSON.stringify({
-                    session_id: this.sessionId,
-                    name: functionName,
-                    parameters: parameters
-                })
-            });
-            
-            if (!response.ok) {
-                throw new Error(`HTTP错误: ${response.status}`);
-            }
-            
-            const data = await response.json();
-            console.log(`MCP工具(${functionName})返回:`, data);
-            
-            // 处理返回结果
-            return data.result?.content || JSON.stringify(data.result);
-        } catch (error) {
-            console.error(`MCP工具调用失败(${functionName}):`, error);
-            return null;
-        }
-    }
-    
-    // 生成唯一会话ID
-    generateSessionId() {
-        return 'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'.replace(/[xy]/g, function(c) {
-            const r = Math.random() * 16 | 0;
-            const v = c === 'x' ? r : (r & 0x3 | 0x8);
-            return v.toString(16);
-        });
-    }
-    
-    // 停止MCP客户端
-    stop() {
-        this.isConnected = false;
-        console.log('MCP客户端已停止');
-    }
-}
-
-// 导出模块
-module.exports = { MCPClientModule };
\ No newline at end of file
diff --git a/live-2d/js/model-interaction.js b/live-2d/js/model-interaction.js
deleted file mode 100644
index 80cbe09..0000000
--- a/live-2d/js/model-interaction.js
+++ /dev/null
@@ -1,280 +0,0 @@
-const { ipcRenderer } = require('electron');
-
-// 模型交互控制器类
-class ModelInteractionController {
-    constructor() {
-        this.model = null;
-        this.app = null;
-        this.interactionWidth = 0;
-        this.interactionHeight = 0;
-        this.interactionX = 0;
-        this.interactionY = 0;
-        this.isDragging = false;
-        this.isDraggingChat = false;
-        this.dragOffset = { x: 0, y: 0 };
-        this.chatDragOffset = { x: 0, y: 0 }
-    }
-
-    // 初始化模型和应用
-    init(model, app) {
-        this.model = model;
-        this.app = app;
-        this.updateInteractionArea();
-        this.setupInteractivity();
-    }
-
-    // 更新交互区域大小和位置
-    updateInteractionArea() {
-        if (!this.model) return;
-        
-        this.interactionWidth = this.model.width / 3;
-        this.interactionHeight = this.model.height * 0.7;
-        this.interactionX = this.model.x + (this.model.width - this.interactionWidth) / 2;
-        this.interactionY = this.model.y + (this.model.height - this.interactionHeight) / 2;
-    }
-
-    // 设置交互性
-    setupInteractivity() {
-        if (!this.model) return;
-        
-        this.model.interactive = true;
-
-        // 覆盖原始的containsPoint方法，自定义交互区域
-        const originalContainsPoint = this.model.containsPoint;
-        this.model.containsPoint = (point) => {
-            
-            const isOverModel = (
-                currentModel && // 确保模型已加载
-                point.x >= this.interactionX &&
-                point.x <= this.interactionX + this.interactionWidth &&
-                point.y >= this.interactionY &&
-                point.y <= this.interactionY + this.interactionHeight
-            );
-
-            // // 检查是否在聊天框内
-            const chatContainer = document.getElementById('text-chat-container');
-            if (!chatContainer) return isOverModel; // 如果聊天框不存在，仅检查模型
-
-            // 获取PIXI应用的view(DOM canvas元素)
-            const pixiView = this.app.renderer.view;
-    
-            // 计算canvas在页面中的位置
-            const canvasRect = pixiView.getBoundingClientRect();
-    
-            // 获取聊天框的DOM位置
-            const chatRect = chatContainer.getBoundingClientRect();
-    
-            // 将DOM坐标转换为PIXI坐标
-            const chatLeftInPixi = (chatRect.left - canvasRect.left) * (pixiView.width / canvasRect.width);
-            const chatRightInPixi = (chatRect.right - canvasRect.left) * (pixiView.width / canvasRect.width);
-            const chatTopInPixi = (chatRect.top - canvasRect.top) * (pixiView.height / canvasRect.height);
-            const chatBottomInPixi = (chatRect.bottom - canvasRect.top) * (pixiView.height / canvasRect.height);
-
-            // const chatRect = chatContainer.getBoundingClientRect();
-            const isOverChat = (
-                point.x >= chatLeftInPixi &&
-                point.x <= chatRightInPixi &&
-                point.y >= chatTopInPixi &&
-                point.y <= chatBottomInPixi
-            );
-
-            
-            return isOverModel || isOverChat;
-        };
-        
-
-        // 鼠标按下事件
-        this.model.on('mousedown', (e) => {
-            const point = e.data.global;
-            if (this.model.containsPoint(point)) {
-                this.isDragging = true;
-                this.dragOffset.x = point.x - this.model.x;
-                this.dragOffset.y = point.y - this.model.y;
-                ipcRenderer.send('set-ignore-mouse-events', {
-                    ignore: false
-                });
-            }
-            
-        });
-
-        // 鼠标移动事件
-        this.model.on('mousemove', (e) => {
-            if (this.isDragging) {
-                const newX = e.data.global.x - this.dragOffset.x;
-                const newY = e.data.global.y - this.dragOffset.y;
-                this.model.position.set(newX, newY);
-                this.updateInteractionArea();
-            }
-        });
-
-        // 全局鼠标释放事件
-        window.addEventListener('mouseup', () => {
-            if (this.isDragging) {
-                this.isDragging = false;
-                setTimeout(() => {
-                    if (!this.model.containsPoint(this.app.renderer.plugins.interaction.mouse.global)) {
-                        ipcRenderer.send('set-ignore-mouse-events', {
-                            ignore: true,
-                            options: { forward: true }
-                        });
-                    }
-                }, 100);
-            }
-        });
-
-        const chatContainer = document.getElementById('text-chat-container');
-
-        // 鼠标按下时开始拖动
-        chatContainer.addEventListener('mousedown', (e) => {
-            // 仅当点击聊天框背景或消息区域时触发拖动（避免误触输入框和按钮）
-            if (e.target === chatContainer || e.target.id === 'chat-messages') {
-                this.isDraggingChat = true;
-                this.chatDragOffset.x = e.clientX - chatContainer.getBoundingClientRect().left;
-                this.chatDragOffset.y = e.clientY - chatContainer.getBoundingClientRect().top;
-                e.preventDefault(); // 防止文本选中
-                ipcRenderer.send('set-ignore-mouse-events', {
-                    ignore: false
-                });
-                
-            }
-        });
-
-        // 鼠标移动时更新位置
-        document.addEventListener('mousemove', (e) => {
-            if (this.isDraggingChat) {
-                chatContainer.style.left = `${e.clientX - this.chatDragOffset.x}px`;
-                chatContainer.style.top = `${e.clientY - this.chatDragOffset.y}px`;
-                this.model.position.set(newX, newY);
-                this.updateInteractionArea();
-            }
-        });
-
-        // 鼠标释放时停止拖动
-        document.addEventListener('mouseup', () => {
-            // this.isDraggingChat = false;
-            if (this.isDraggingChat) {
-                this.isDraggingChat = false;
-                setTimeout(() => {
-                    if (!this.model.containsPoint(this.app.renderer.plugins.interaction.mouse.global)) {
-                        ipcRenderer.send('set-ignore-mouse-events', {
-                            ignore: true,
-                            options: { forward: true }
-                        });
-                    }
-                }, 100);
-            }
-        });
-
-
-// 拖动结束时，再次检查穿透状态
-// window.addEventListener('mouseup', () => {
-//     if (this.isDraggingChat) {
-//         this.isDraggingChat = false;
-//         this.updateMouseIgnore(); // 确保拖动结束后状态正确
-//     }
-// });
-
-// 鼠标离开事件
-// document.addEventListener('mouseout', () => {
-//     if (!this.isDraggingChat) {
-//         ipcRenderer.send('set-ignore-mouse-events', {
-//             ignore: true,
-//             options: { forward: true }
-//         });
-//     }
-// });
-
-        // 鼠标悬停事件
-        this.model.on('mouseover', () => {
-            if (this.model.containsPoint(this.app.renderer.plugins.interaction.mouse.global)) {
-                ipcRenderer.send('set-ignore-mouse-events', {
-                    ignore: false
-                });
-            }
-        });
-
-        // 鼠标离开事件
-        this.model.on('mouseout', () => {
-            if (!this.isDragging) {
-                ipcRenderer.send('set-ignore-mouse-events', {
-                    ignore: true,
-                    options: { forward: true }
-                });
-            }
-        });
-
-        // 鼠标点击事件
-        this.model.on('click', () => {
-            if (this.model.containsPoint(this.app.renderer.plugins.interaction.mouse.global) && this.model.internalModel) {
-                this.model.motion("Tap");
-                this.model.expression();
-            }
-        });
-
-        // 鼠标滚轮事件（缩放功能）
-        window.addEventListener('wheel', (e) => {
-            if (this.model.containsPoint(this.app.renderer.plugins.interaction.mouse.global)) {
-                e.preventDefault();
-
-                const scaleChange = e.deltaY > 0 ? 0.9 : 1.1;
-                const currentScale = this.model.scale.x;
-                const newScale = currentScale * scaleChange;
-
-                const minScale = this.model.scale.x * 0.3;
-                const maxScale = this.model.scale.x * 3.0;
-
-                if (newScale >= minScale && newScale <= maxScale) {
-                    this.model.scale.set(newScale);
-
-                    const oldWidth = this.model.width / scaleChange;
-                    const oldHeight = this.model.height / scaleChange;
-                    const deltaWidth = this.model.width - oldWidth;
-                    const deltaHeight = this.model.height - oldHeight;
-
-                    this.model.x -= deltaWidth / 2;
-                    this.model.y -= deltaHeight / 2;
-                    this.updateInteractionArea();
-                }
-            }
-        }, { passive: false });
-
-        // 窗口大小改变事件
-        window.addEventListener('resize', () => {
-            if (this.app && this.app.renderer) {
-                this.app.renderer.resize(window.innerWidth * 2, window.innerHeight * 2);
-                this.app.stage.position.set(window.innerWidth / 2, window.innerHeight / 2);
-                this.app.stage.pivot.set(window.innerWidth / 2, window.innerHeight / 2);
-                this.updateInteractionArea();
-            }
-        });
-    }
-
-    // 设置嘴部动画
-    setMouthOpenY(v) {
-        if (!this.model) return;
-        
-        try {
-            v = Math.max(0, Math.min(v, 3.0));
-            const paramId = 'ParamMouthOpenY';
-            const coreModel = this.model.internalModel.coreModel;
-            coreModel.setParameterValueById(paramId, v);
-        } catch (error) {
-            console.error('设置嘴型参数失败:', error);
-        }
-    }
-
-    // 初始化模型位置和大小
-    setupInitialModelProperties(scaleMultiplier = 2.3) {
-        if (!this.model || !this.app) return;
-        
-        const scaleX = (window.innerWidth * scaleMultiplier) / this.model.width;
-        const scaleY = (window.innerHeight * scaleMultiplier) / this.model.height;
-        this.model.scale.set(Math.min(scaleX, scaleY));
-
-        this.model.y = window.innerHeight * 0.8;
-        this.model.x = window.innerWidth * 1.35;
-        this.updateInteractionArea();
-    }
-}
-
-module.exports = { ModelInteractionController };
\ No newline at end of file
diff --git a/live-2d/js/tts-processor.js b/live-2d/js/tts-processor.js
deleted file mode 100644
index 250b0d9..0000000
--- a/live-2d/js/tts-processor.js
+++ /dev/null
@@ -1,637 +0,0 @@
-// 改进的文本处理器 - 与情绪动作同步
-class EnhancedTextProcessor {
-   constructor(ttsUrl, onAudioDataCallback, onStartCallback, onEndCallback, config = null) {
-       this.config = config || {};
-       this.ttsUrl = ttsUrl;
-       this.onAudioDataCallback = onAudioDataCallback;
-       this.onStartCallback = onStartCallback;
-       this.onEndCallback = onEndCallback;
-       this.language = this.config.tts?.language || "zh"; // 从配置中获取语言设置
-
-       // 单一队列设计
-       this.textSegmentQueue = [];    // 待处理的文本段
-       this.audioDataQueue = [];      // 已获得音频数据但尚未播放
-
-       // 处理状态标志
-       this.isProcessing = false;     // 正在处理文本段
-       this.isPlaying = false;        // 正在播放音频
-       this.shouldStop = false;       // 停止标志
-
-       // 音频处理相关
-       this.audioContext = null;
-       this.analyser = null;
-       this.dataArray = null;
-       this.currentAudio = null;
-
-       // 标点符号定义
-       this.punctuations = [',', '。', '，', '？', '!', '！', '；', ';', '：', ':'];
-
-       // 当前要显示的完整文本
-       this.currentFullText = '';
-
-       // 临时存储未处理的文本片段
-       this.pendingSegment = '';
-
-       // 文字同步相关
-       this.llmFullResponse = '';     // LLM返回的完整回复文本
-       this.displayedText = '';       // 当前已经显示的文本
-       this.currentSegmentText = '';  // 当前正在播放的音频段落对应的文本
-       this.syncTextQueue = [];       // 文本段落队列，与音频段落队列对应
-
-       // 情绪动作同步相关
-       this.emotionMapper = null;     // 情绪动作映射器引用
-       this.currentEmotionMarkers = []; // 当前段落的情绪标记
-
-       // 用于中断的计时器引用
-       this._textAnimInterval = null;
-       this._renderFrameId = null;
-
-       // 启动处理线程
-       this.startProcessingThread();
-       this.startPlaybackThread();
-   }
-
-   // 设置情绪动作映射器
-   setEmotionMapper(emotionMapper) {
-       this.emotionMapper = emotionMapper;
-   }
-
-   // 初始化音频上下文
-   async initAudioContext() {
-       if (!this.audioContext) {
-           this.audioContext = new (window.AudioContext || window.webkitAudioContext)();
-           this.analyser = this.audioContext.createAnalyser();
-           this.analyser.fftSize = 256;
-           this.dataArray = new Uint8Array(this.analyser.frequencyBinCount);
-       }
-   }
-
-   // 启动文本处理线程 - 顺序处理文本段
-   startProcessingThread() {
-       const processNextSegment = async () => {
-           if (this.shouldStop) return;
-
-           // 当有文本段待处理且当前没有处理中的文本段时
-           if (this.textSegmentQueue.length > 0 && !this.isProcessing) {
-               this.isProcessing = true;
-               const segment = this.textSegmentQueue.shift();
-
-               try {
-                   // 将文本段添加到同步队列，用于后续文本动画显示
-                   this.syncTextQueue.push(segment);
-
-                   // 处理单个文本段
-                   const audioData = await this.convertTextToSpeech(segment);
-                   if (audioData) {
-                       // 将音频数据和对应的文本作为一个包加入队列
-                       this.audioDataQueue.push({
-                           audio: audioData,
-                           text: segment
-                       });
-                   }
-               } catch (error) {
-                   console.error('TTS处理错误:', error);
-               }
-
-               this.isProcessing = false;
-           }
-
-           // 继续检查队列
-           setTimeout(processNextSegment, 50);
-       };
-
-       // 开始处理循环
-       processNextSegment();
-   }
-
-   // 启动音频播放线程 - 顺序播放音频
-   startPlaybackThread() {
-       const playNextAudio = async () => {
-           if (this.shouldStop) return;
-
-           // 当有音频数据待播放且当前没有播放中的音频时
-           if (this.audioDataQueue.length > 0 && !this.isPlaying) {
-               const audioPackage = this.audioDataQueue.shift();
-
-               // 设置当前段落的文本，用于文字动画
-               this.currentSegmentText = audioPackage.text;
-                //翻译
-                this.currentSegmentText = await this.translate(this.currentSegmentText);
-
-               // 播放音频并同步显示文本
-               await this.playAudioWithTextSync(audioPackage.audio);
-           }
-
-           // 继续检查队列
-           setTimeout(playNextAudio, 50);
-       };
-
-       // 开始播放循环
-       playNextAudio();
-   }
-
-   // 将文本转换为语音
-   async convertTextToSpeech(text) {
-       try {
-           // 移除括号内容和星号包裹的内容用于TTS
-           const textForTTS = text
-               .replace(/<[^>]+>/g, '')     // 不移除情绪标签
-               .replace(/（.*?）|\(.*?\)/g, '')  // 移除括号内容
-               .replace(/\*.*?\*/g, '');         // 移除星号包裹内容
-
-           const response = await fetch(this.ttsUrl, {
-               method: 'POST',
-               headers: {
-                   'Content-Type': 'application/json'
-               },
-               body: JSON.stringify({
-                   text: textForTTS,
-                   text_language: this.language  // 使用配置中的语言
-               })
-           });
-
-           if (!response.ok) {
-               throw new Error('TTS请求失败: ' + response.status);
-           }
-
-           return await response.blob();
-       } catch (error) {
-           console.error('TTS转换错误:', error);
-           return null;
-       }
-   }
-
-     async translate(text){
-        // 翻译文本
-        if (this.config.translator.enabled){
-            // LLM配置
-            const {GoogleGenAI} = require("@google/genai");
-            this.API_KEY = this.config.llm.api_key;
-            this.API_URL = this.config.llm.api_url;
-            this.MODEL = this.config.llm.model;
-            this.provider = this.config.llm.provider;
-            if (this.provider === 'google_aistudio')
-                this.ai = new GoogleGenAI({ apiKey: this.API_KEY });
-                this.chat = this.ai.chats.create({
-                model: this.MODEL,
-                history: [
-                    ],
-                });
-
-            // process.stdout.write("fullResponse");
-            process.stdout.write("\nOriginal:" + text);
-            const response = await this.ai.models.generateContent({
-                    model: this.MODEL,
-                    contents: text,
-                    config: {
-                        systemInstruction: this.config.translator.prompt
-                    },
-                });
-                text = response.text;
-                // fullResponse = response.text;
-                process.stdout.write("\nTranslated:" + text);
-            }
-        return text
-    }
-   // 播放单个音频片段，同时实现文本动画同步和情绪动作同步
-   async playAudioWithTextSync(audioBlob) {
-       if (!audioBlob) return;
-
-       await this.initAudioContext();
-        return new Promise(async (resolve) => {
-           if (this.shouldStop) {
-               resolve();
-               return;
-           }
-
-           this.isPlaying = true;
-           const audioUrl = URL.createObjectURL(audioBlob);
-           const audio = new Audio(audioUrl);
-           this.currentAudio = audio;
-
-           // 触发开始回调
-           if (this.onStartCallback) {
-               this.onStartCallback();
-           }
-
-           // 设置音频分析
-           const source = this.audioContext.createMediaElementSource(audio);
-           source.connect(this.analyser);
-           this.analyser.connect(this.audioContext.destination);
-
-           // 预处理当前段落的文本，提取情绪标记
-           let segmentText = this.currentSegmentText;
-           let emotionMarkers = [];
-
-           // 如果存在情绪映射器，处理情绪标签
-           if (this.emotionMapper) {
-               // 使用情绪映射器预处理文本，获取情绪标记
-               const processedInfo = this.emotionMapper.prepareTextForTTS(segmentText);
-               segmentText = processedInfo.text; // 更新为去除情绪标签的纯文本
-               emotionMarkers = processedInfo.emotionMarkers; // 保存情绪标记
-
-               // 保存情绪标记用于后续动作触发
-               this.currentEmotionMarkers = [...emotionMarkers];
-
-               console.log(`段落文本: "${segmentText}"`);
-               console.log(`情绪标记: ${JSON.stringify(emotionMarkers)}`);
-           }
-
-           const segmentLength = segmentText.length;
-           let charDisplayIndex = 0;
-
-           // 动态显示文本的计时器
-           let textAnimInterval = null;
-
-           // 更新AI的嘴巴动作
-           const updateMouth = () => {
-               if (this.shouldStop || !this.currentAudio) return;
-
-               this.analyser.getByteFrequencyData(this.dataArray);
-               const sampleCount = this.dataArray.length / 2;
-               let sum = 0;
-               for (let i = 0; i < sampleCount; i++) {
-                   sum += this.dataArray[i];
-               }
-               const average = sum / sampleCount;
-
-               // 使用平方根函数使动画更自然
-               const mouthOpenValue = Math.pow((average / 256), 0.8) * 1;
-
-               if (this.onAudioDataCallback) {
-                   this.onAudioDataCallback(mouthOpenValue);
-               }
-
-               // 持续更新
-               if (this.currentAudio && !this.shouldStop) {
-                   this._renderFrameId = requestAnimationFrame(updateMouth);
-               }
-           };
-
-           // 开始文本动画
-           const startTextAnimation = () => {
-               // 计算每个字符显示的间隔时间（根据音频长度和文本长度）
-               const audioDuration = audio.duration * 1000; // 毫秒
-               let charInterval = audioDuration / segmentLength;
-
-               // 设置最小和最大字符间隔，以确保动画自然
-               charInterval = Math.max(30, Math.min(200, charInterval));
-
-               textAnimInterval = setInterval(() => {
-                   if (this.shouldStop) {
-                       if (textAnimInterval) {
-                           clearInterval(textAnimInterval);
-                           textAnimInterval = null;
-                       }
-                       return;
-                   }
-
-                   if (charDisplayIndex < segmentLength) {
-                       // 逐步增加显示的文本
-                       charDisplayIndex++;
-
-                       // 根据当前显示位置触发情绪动作
-                       if (this.emotionMapper && this.currentEmotionMarkers.length > 0) {
-                           this.emotionMapper.triggerEmotionByTextPosition(
-                               charDisplayIndex,
-                               segmentLength,
-                               this.currentEmotionMarkers
-                           );
-                       }
-
-                       // 修改: 完整显示之前所有的文本 + 当前段落的动画部分
-                       const currentDisplay = this.displayedText + segmentText.substring(0, charDisplayIndex);
-
-                       // 更新字幕显示
-                       if (typeof showSubtitle === 'function') {
-                           showSubtitle(`Seraphim: ${currentDisplay}`);
-                           // 确保滚动到底部
-                           document.getElementById('subtitle-container').scrollTop =
-                               document.getElementById('subtitle-container').scrollHeight;
-                       }
-                   }
-               }, charInterval);
-
-               // 保存计时器引用以便在中断时清除
-               this._textAnimInterval = textAnimInterval;
-           };
-
-           audio.oncanplaythrough = () => {
-               startTextAnimation();
-           };
-
-           audio.onplay = () => {
-               updateMouth();
-           };
-
-           audio.onended = () => {
-               if (this.onAudioDataCallback) {
-                   this.onAudioDataCallback(0); // 关闭嘴巴
-               }
-
-               // 清除文本动画计时器
-               if (textAnimInterval) {
-                   clearInterval(textAnimInterval);
-                   textAnimInterval = null;
-                   this._textAnimInterval = null;
-               }
-
-               // 取消渲染帧
-               if (this._renderFrameId) {
-                   cancelAnimationFrame(this._renderFrameId);
-                   this._renderFrameId = null;
-               }
-
-               // 音频播放完毕后，将当前段落全部显示
-               this.displayedText += segmentText;
-               if (typeof showSubtitle === 'function') {
-                   showSubtitle(`Seraphim: ${this.displayedText}`);
-               }
-
-               URL.revokeObjectURL(audioUrl);
-               this.currentAudio = null;
-               this.isPlaying = false;
-
-               // 清空当前段落的情绪标记
-               this.currentEmotionMarkers = [];
-
-               // 检查是否所有文本都已处理和播放完成
-               if (this.audioDataQueue.length === 0 &&
-                   this.textSegmentQueue.length === 0 &&
-                   !this.isProcessing &&
-                   this.pendingSegment.trim() === '') {
-
-                   // 修复：播放完成后，设置一个3秒的延迟然后隐藏字幕
-                   setTimeout(() => {
-                       if (typeof hideSubtitle === 'function') {
-                           hideSubtitle();
-                       }
-                   }, 1000);
-
-                   if (this.onEndCallback) {
-                       this.onEndCallback();
-                   }
-               }
-
-               resolve();
-           };
-
-           audio.onerror = (e) => {
-               console.error('音频播放错误:', e);
-
-               // 清除文本动画计时器
-               if (textAnimInterval) {
-                   clearInterval(textAnimInterval);
-                   textAnimInterval = null;
-                   this._textAnimInterval = null;
-               }
-
-               // 取消渲染帧
-               if (this._renderFrameId) {
-                   cancelAnimationFrame(this._renderFrameId);
-                   this._renderFrameId = null;
-               }
-
-               URL.revokeObjectURL(audioUrl);
-               this.currentAudio = null;
-               this.isPlaying = false;
-               resolve();
-           };
-
-           // 播放
-           audio.play().catch(error => {
-               console.error('播放失败:', error);
-
-               // 清除文本动画计时器
-               if (textAnimInterval) {
-                   clearInterval(textAnimInterval);
-                   textAnimInterval = null;
-                   this._textAnimInterval = null;
-               }
-
-               // 取消渲染帧
-               if (this._renderFrameId) {
-                   cancelAnimationFrame(this._renderFrameId);
-                   this._renderFrameId = null;
-               }
-
-               this.currentAudio = null;
-               this.isPlaying = false;
-               resolve();
-           });
-       });
-   }
-
-   // 添加流式文本，实时进行分段处理
-   addStreamingText(text) {
-       if (this.shouldStop) return;
-
-       // 更新LLM的完整响应文本
-       this.llmFullResponse += text;
-
-       // 将新文本追加到待处理的段落中
-       this.pendingSegment += text;
-
-       // 逐字符处理，只在标点符号处分段
-       let processedSegment = '';
-       for (let i = 0; i < this.pendingSegment.length; i++) {
-           const char = this.pendingSegment[i];
-           processedSegment += char;
-
-           // 遇到标点符号时分段
-           if (this.punctuations.includes(char) && processedSegment.trim()) {
-               this.textSegmentQueue.push(processedSegment);
-               processedSegment = '';
-           }
-       }
-
-       // 保存未处理的文本段
-       this.pendingSegment = processedSegment;
-   }
-
-   // 完成流式文本处理，确保所有文本都被处理
-   finalizeStreamingText() {
-       // 添加消息到聊天框
-       const chatMessages = document.getElementById('chat-messages');
-       if (chatMessages) {
-           const messageElement = document.createElement('div');
-           messageElement.innerHTML = `<strong>Seraphim:</strong> ${this.llmFullResponse}`;
-           chatMessages.appendChild(messageElement);
-           chatMessages.scrollTop = chatMessages.scrollHeight;
-       }
-
-       // 确保任何剩余的文本都被处理
-       if (this.pendingSegment.trim()) {
-           this.textSegmentQueue.push(this.pendingSegment);
-           this.pendingSegment = '';
-       }
-   }
-
-   // 处理完整文本（兼容旧的调用方式）
-   async processTextToSpeech(text) {
-       if (!text.trim()) return;
-
-       this.reset();
-       this.llmFullResponse = text;
-
-       // 不再直接显示文本，而是等待音频播放时显示
-
-       // 分段处理文本
-       let currentSegment = '';
-       for (let char of text) {
-           currentSegment += char;
-           if (this.punctuations.includes(char) && currentSegment.trim()) {
-               this.textSegmentQueue.push(currentSegment);
-               currentSegment = '';
-           }
-       }
-
-       // 处理末尾没有标点的文本
-       if (currentSegment.trim()) {
-           this.textSegmentQueue.push(currentSegment);
-       }
-   }
-
-   // 重置所有状态
-   reset() {
-       this.llmFullResponse = '';
-       this.displayedText = '';
-       this.currentSegmentText = '';
-       this.pendingSegment = '';
-       this.syncTextQueue = [];
-       this.currentEmotionMarkers = [];
-
-       // 停止当前播放
-       if (this.currentAudio) {
-           this.currentAudio.pause();
-           this.currentAudio = null;
-       }
-
-       // 清除所有计时器
-       if (this._textAnimInterval) {
-           clearInterval(this._textAnimInterval);
-           this._textAnimInterval = null;
-       }
-
-       if (this._renderFrameId) {
-           cancelAnimationFrame(this._renderFrameId);
-           this._renderFrameId = null;
-       }
-
-       // 清空所有队列
-       this.textSegmentQueue = [];
-       this.audioDataQueue = [];
-
-       // 重置状态
-       this.isPlaying = false;
-       this.isProcessing = false;
-       this.shouldStop = false;
-
-       // 重置嘴部动作
-       if (this.onAudioDataCallback) {
-           this.onAudioDataCallback(0);
-       }
-   }
-
-   // 立即打断TTS播放
-   interrupt() {
-       console.log('打断TTS播放...');
-
-       // 设置打断标志立即生效
-       this.shouldStop = true;
-
-       // 查找并清除所有可能的动画计时器
-       if (this._textAnimInterval) {
-           clearInterval(this._textAnimInterval);
-           this._textAnimInterval = null;
-       }
-
-       // 取消可能正在进行的渲染帧
-       if (this._renderFrameId) {
-           cancelAnimationFrame(this._renderFrameId);
-           this._renderFrameId = null;
-       }
-
-       // 立即停止当前音频播放并清除所有事件监听器
-       if (this.currentAudio) {
-           try {
-               // 移除所有事件监听器，防止onended等继续触发
-               this.currentAudio.onended = null;
-               this.currentAudio.onplay = null;
-               this.currentAudio.oncanplaythrough = null;
-               this.currentAudio.onerror = null;
-
-               // 暂停并释放音频
-               this.currentAudio.pause();
-               this.currentAudio.src = ""; // 清空音频源
-               this.currentAudio = null;
-           } catch (e) {
-               console.error('停止音频出错:', e);
-           }
-       }
-
-       // 清空所有队列和缓冲区
-       this.textSegmentQueue = [];
-       this.audioDataQueue = [];
-       this.pendingSegment = '';
-       this.llmFullResponse = '';
-       this.displayedText = '';
-       this.currentSegmentText = '';
-       this.syncTextQueue = [];
-       this.currentEmotionMarkers = [];
-
-       // 重置状态标志
-       this.isPlaying = false;
-       this.isProcessing = false;
-
-       // 恢复嘴形到默认状态
-       if (this.onAudioDataCallback) {
-           this.onAudioDataCallback(0); // 关闭嘴巴
-       }
-
-       // 立即隐藏字幕
-       if (typeof hideSubtitle === 'function') {
-           hideSubtitle();
-       }
-
-       // 执行结束回调，确保系统状态复位
-       if (this.onEndCallback) {
-           this.onEndCallback();
-       }
-
-       // 延迟重置shouldStop标志，确保所有处理都已停止
-       setTimeout(() => {
-           // 确保可以接收新的输入
-           this.shouldStop = false;
-
-           // 重新启动处理线程
-           this.startProcessingThread();
-           this.startPlaybackThread();
-
-           console.log('TTS处理器完全重置完成');
-       }, 300);
-   }
-
-   // 立即停止所有处理
-   stop() {
-       this.shouldStop = true;
-       this.reset();
-
-       // 隐藏字幕
-       if (typeof hideSubtitle === 'function') {
-           hideSubtitle();
-       }
-
-       if (this.onEndCallback) {
-           this.onEndCallback();
-       }
-   }
-
-   // 判断是否正在播放
-   isPlaying() {
-       return this.isPlaying || this.isProcessing || this.textSegmentQueue.length > 0 || this.audioDataQueue.length > 0;
-   }
-}
-
-// 导出TTS处理器类
-module.exports = { EnhancedTextProcessor };
\ No newline at end of file
diff --git a/live-2d/js/voice-chat.js b/live-2d/js/voice-chat.js
deleted file mode 100644
index d899e24..0000000
--- a/live-2d/js/voice-chat.js
+++ /dev/null
@@ -1,775 +0,0 @@
-const { ipcRenderer } = require('electron');
-const fs = require('fs');
-const path = require('path');
-const os = require('os');
-const {GoogleGenAI, createUserContent, createPartFromUri} = require("@google/genai");
-
-class VoiceChatInterface {
-    constructor(vadUrl, asrUrl, ttsProcessor, showSubtitle, hideSubtitle, config) {
-        // 直接使用传入的配置
-        this.config = config;
-        
-        // LLM配置
-        this.API_KEY = this.config.llm.api_key;
-        this.API_URL = this.config.llm.api_url;
-        this.MODEL = this.config.llm.model;
-                this.provider = this.config.llm.provider;
-        if (this.provider === 'google_aistudio')
-            this.ai = new GoogleGenAI({ apiKey: this.API_KEY });
-            this.chat = this.ai.chats.create({
-            model: this.MODEL,
-            history: [
-                ],
-            });
-
-        
-        this.ttsProcessor = ttsProcessor;
-        this.showSubtitle = showSubtitle;
-        this.hideSubtitle = hideSubtitle;
-        
-        // 初始化ASR处理器
-        const { ASRProcessor } = require('./asr-processor.js');
-        this.asrProcessor = new ASRProcessor(vadUrl, asrUrl);
-        
-        // 上下文限制相关属性
-        this.maxContextMessages = this.config.context.max_messages;
-        this.enableContextLimit = this.config.context.enable_limit;
-        
-        // 添加截图相关的属性
-        this.screenshotEnabled = this.config.vision.enabled;
-        this.screenshotPath = this.config.vision.screenshot_path;
-        this.visionCheckUrl = this.config.vision.check_url;
-        this.autoScreenshot = this.config.vision.auto_screenshot || false; // 新增：默认截图功能
-
-        // 记忆文件路径
-        this.memoryFilePath = this.config.memory.file_path;
-        this.memoryCheckUrl = this.config.memory.check_url;
-
-        // 模型引用
-        this.model = null;
-
-        // 情绪动作映射器引用
-        this.emotionMapper = null;
-
-        // 确保对话记录文件存在
-        const dialogLogPath = path.join(__dirname, '..', '对话记录.txt');
-        try {
-            // 检查文件是否存在
-            if (!fs.existsSync(dialogLogPath)) {
-                fs.writeFileSync(dialogLogPath, '', 'utf8');
-            }
-
-            // 添加新会话的开始标记 - 只精确到天
-            const currentDate = new Date().toISOString().split('T')[0]; // 格式: YYYY-MM-DD
-            const sessionStart = `=== 新会话开始：${currentDate} ===\n`;
-            fs.appendFileSync(dialogLogPath, sessionStart, 'utf8');
-            console.log('对话记录文件已准备好');
-        } catch (error) {
-            console.error('准备对话记录文件失败:', error);
-        }
-
-        // 读取记忆库文件内容
-        let memoryContent = "";
-        try {
-            memoryContent = fs.readFileSync(this.memoryFilePath, 'utf8');
-            console.log('成功读取记忆库内容');
-        } catch (error) {
-            console.error('读取记忆库文件失败:', error);
-            memoryContent = "无法读取记忆库内容";
-        }
-
-        // 获取系统提示词并添加记忆库内容
-        const baseSystemPrompt = this.config.llm.system_prompt;
-
-        const systemPrompt = `${baseSystemPrompt}这些数据里面是有关用户的各种信息。你可以观测，在必要的时候参考这些内容，正常普通的对话不要提起：
-${memoryContent}`;
-
-        // 初始化消息数组，只包含系统消息
-        this.messages = [
-            {
-                'role': 'system',
-                'content': systemPrompt
-            }
-        ];
-
-        // 设置ASR回调
-        this.asrProcessor.setOnSpeechRecognized(async (text) => {
-            // 显示用户ASR字幕的功能
-            this.showSubtitle(`用户: ${text}`, 3000);
-
-            // 设置锁定标志，防止主动对话插入
-            global.isProcessingUserInput = true;
-
-            try {
-                // 检查消息是否需要记忆，并保存
-                const needMemory = await this.checkMessageForMemory(text);
-                if (needMemory) {
-                    await this.saveToMemory(text);
-                    console.log('用户消息已保存到记忆库');
-                } else {
-                    console.log('用户消息不需要保存到记忆库');
-                }
-
-                await this.sendToLLM(text);
-            } finally {
-                // 无论成功与否，处理完毕后都解除锁定
-                global.isProcessingUserInput = false;
-
-                // 获取最后一次用户消息和AI回复
-                const lastUserMsg = this.messages.filter(m => m.role === 'user').pop();
-                const lastAIMsg = this.messages.filter(m => m.role === 'assistant').pop();
-
-                // 只追加新的对话内容，而不是覆盖整个文件
-                if (lastUserMsg && lastAIMsg) {
-                    // 构建要追加的新对话内容 - 不包含时间戳和空行
-                    const newContent = `【用户】: ${lastUserMsg.content}\n【Seraphim】: ${lastAIMsg.content}\n`;
-
-                    // 追加到对话记录文件
-                    try {
-                        fs.appendFileSync(
-                            path.join(__dirname, '..', '对话记录.txt'),
-                            newContent,
-                            'utf8'
-                        );
-                    } catch (error) {
-                        console.error('保存对话记录失败:', error);
-                    }
-                }
-            }
-        });
-    }
-
-    // 设置模型
-    setModel(model) {
-        this.model = model;
-        console.log('模型已设置到VoiceChat');
-    }
-
-    // 设置情绪动作映射器
-    setEmotionMapper(emotionMapper) {
-        this.emotionMapper = emotionMapper;
-        console.log('情绪动作映射器已设置到VoiceChat');
-    }
-
-    // 检查消息是否需要记忆
-    async checkMessageForMemory(text) {
-        try {
-            const response = await fetch(`${this.memoryCheckUrl}?text=${encodeURIComponent(text)}`, {
-                method: 'POST'
-            });
-
-            if (!response.ok) {
-                throw new Error('记忆检查API请求失败');
-            }
-
-            const data = await response.json();
-            console.log('记忆检查结果:', data);
-            return data["需要检索"] === "是";
-        } catch (error) {
-            console.error('记忆检查错误:', error);
-            return false;
-        }
-    }
-
-    // 保存消息到记忆文件
-    async saveToMemory(text) {
-        try {
-            const timestamp = new Date().toISOString().replace('T', ' ').substring(0, 19);
-            const memoryEntry = `[${timestamp}] ${text}\n`;
-
-            fs.appendFileSync(this.memoryFilePath, memoryEntry, 'utf8');
-            console.log('已保存到记忆文件:', text);
-            return true;
-        } catch (error) {
-            console.error('保存记忆失败:', error);
-            return false;
-        }
-    }
-
-    // 暂停录音
-    async pauseRecording() {
-        this.asrProcessor.pauseRecording();
-        console.log('Recording paused due to TTS playback');
-    }
-
-    // 恢复录音
-    async resumeRecording() {
-        this.asrProcessor.resumeRecording();
-        console.log('Recording resumed after TTS playback, ASR unlocked');
-    }
-
-    // 设置上下文限制
-    setContextLimit(enable) {
-        this.enableContextLimit = enable;
-        if (enable) {
-            this.trimMessages();
-        }
-    }
-
-    // 设置最大上下文消息数
-    setMaxContextMessages(count) {
-        if (count < 1) throw new Error('最大消息数不能小于1');
-        this.maxContextMessages = count;
-        if (this.enableContextLimit) {
-            this.trimMessages();
-        }
-    }
-
-    // 裁剪消息 - 修复上下文复读问题
-    trimMessages() {
-        if (!this.enableContextLimit) return;
-
-        // 获取系统消息（始终保留）
-        const systemMessages = this.messages.filter(msg => msg.role === 'system');
-
-        // 获取非系统消息（可能需要裁剪）
-        const nonSystemMessages = this.messages.filter(msg => msg.role !== 'system');
-
-        // 调试日志
-        console.log(`裁剪前: 系统消息 ${systemMessages.length} 条, 非系统消息 ${nonSystemMessages.length} 条`);
-
-        // 只保留最新的 maxContextMessages 条非系统消息
-        const recentMessages = nonSystemMessages.slice(-this.maxContextMessages);
-
-        // 重构消息数组
-        this.messages = [...systemMessages, ...recentMessages];
-
-        console.log(`裁剪后: 消息总数 ${this.messages.length} 条, 非系统消息 ${recentMessages.length} 条`);
-    }
-
-    // 添加截图功能
-    async takeScreenshot() {
-        try {
-            // 请求主进程进行截图，不显示任何提示
-            const filepath = await ipcRenderer.invoke('take-screenshot', this.screenshotPath);
-            console.log('截图已保存:', filepath);
-            return filepath;
-        } catch (error) {
-            console.error('截图错误:', error);
-            throw error;
-        }
-    }
-
-    // 将图片转换为base64编码
-    async imageToBase64(imagePath) {
-        return new Promise((resolve, reject) => {
-            fs.readFile(imagePath, (err, data) => {
-                if (err) {
-                    console.error('读取图片失败:', err);
-                    reject(err);
-                    return;
-                }
-                const base64Image = Buffer.from(data).toString('base64');
-                resolve(base64Image);
-            });
-        });
-    }
-
-    // 判断是否需要截图
-    async shouldTakeScreenshot(text) {
-        if (!this.screenshotEnabled) return false;
-
-        // 如果开启了自动截图，直接返回 true
-        if (this.autoScreenshot) {
-            console.log('自动截图模式已开启，将为本次对话截图');
-            return true;
-        }
-
-        // 否则使用原有的智能判断逻辑
-        try {
-            const url = `${this.visionCheckUrl}?text=${encodeURIComponent(text)}`;
-            const response = await fetch(url, {
-                method: 'POST',
-            });
-
-            const data = await response.json();
-            const result = data["需要视觉"];
-            console.log(`截图判断结果: ${result}`);
-
-            return result === "是";
-        } catch (error) {
-            console.error('判断截图错误:', error);
-            return false;
-        }
-    }
-
-    // 开始录音
-    async startRecording() {
-        await this.asrProcessor.startRecording();
-    }
-
-    // 停止录音
-    stopRecording() {
-        this.asrProcessor.stopRecording();
-    }
-
-    // 发送消息到LLM
-    async sendToLLM(prompt) {
-        try {
-            // 重置TTS处理器的状态
-            this.ttsProcessor.reset();
-
-            // 清除之前的字幕，准备显示新对话
-            // 这里不直接隐藏字幕，因为用户的ASR字幕还在显示中
-
-            let fullResponse = "";
-
-            // 创建新的消息数组，确保不会修改原始消息
-            let messagesForAPI = JSON.parse(JSON.stringify(this.messages));
-
-            // 判断是否需要截图
-            const needScreenshot = await this.shouldTakeScreenshot(prompt);
-
-            // 保存用户消息到上下文（只保存文本）
-            this.messages.push({'role': 'user', 'content': prompt});
-
-            // 先进行裁剪，确保只保留最新的消息
-            if (this.enableContextLimit) {
-                this.trimMessages();
-                // 重建API消息数组，基于裁剪后的消息
-                messagesForAPI = JSON.parse(JSON.stringify(this.messages));
-            }
-
-            
-            // 调试消息数组
-            console.log(`发送给LLM的消息数: ${messagesForAPI.length}`);
-
-            if (this.provider === 'google_aistudio'){
-                try {
-                    // 如果需要截图，创建多模态消息
-                    let config = {message: prompt,
-                        config: {
-                            systemInstruction: this.messages[0].content,
-                        }}
-                    let result;
-
-                    if (needScreenshot) {
-                        try {
-                            console.log("需要截图");
-                            
-                            const screenshotPath = await this.takeScreenshot();
-
-                            // 处理Google AI Studio的截图
-                            const image = await this.ai.files.upload({
-                                file: screenshotPath,
-                            });
-                            console.log("上传截图成功:", image.uri);
-
-                            const config_pic = {
-                                model: this.MODEL,
-                                config: {
-                                    systemInstruction: this.messages[0].content,
-                                },
-                                contents: [
-                                    createUserContent([
-                                        prompt,
-                                        createPartFromUri(image.uri, image.mimeType),
-                                    ]),
-                                ]
-                            }
-                            process.stdout.write(prompt);
-                            result = await this.ai.models.generateContentStream(config_pic)
-                            // result = await this.chat.sendMessageStream(message=prompt, config=config)
-                            // process.stdout.write("su");
-                        } catch (error) {
-                            console.error("截图处理失败:", error);
-                            // 如果截图失败，使用纯文本消息，已经设置好了
-                            config = {message: prompt,
-                                config: {
-                                    systemInstruction: this.messages[0].content,
-                                }
-                            }
-                            process.stdout.write(error);
-                            result = await this.chat.sendMessageStream(config);
-                        }
-                    }
-                    else{
-                        // const result = await this.chat.sendMessageStream(config);
-                        result = await this.chat.sendMessageStream(config);
-                    }
-                    
-                    for await (const chunk of result) {
-                        fullResponse += chunk.text;
-                        this.ttsProcessor.addStreamingText(chunk.text);
-                        process.stdout.write(chunk.text);
-                        process.stdout.write("_".repeat(80));
-                    }
-
-                    // if (1){
-                    //     process.stdout.write("fullResponse");
-                    //     const response = await this.ai.models.generateContent({
-                    //         model: "gemini-2.0-flash",
-                    //         contents: fullResponse,
-                    //         config: {
-                    //             systemInstruction: `You are a highly skilled and precise translation engine. Your sole task is to translate the provided Japanese text accurately and fluently into Simplified Chinese.
-                    //                 **Instructions:**
-                    //                 1.  **Output Format:** ONLY output the translated Simplified Chinese text. Do NOT include the original Japanese text in your response. Do NOT add any prefixes, suffixes, explanations, or any other text体が translated content itself.
-                    //                 2.  **Accuracy and Fluency:** Prioritize natural-sounding and contextually appropriate Simplified Chinese. Maintain the original meaning and tone of the Japanese text as closely as possible.
-                    //                 3.  **Target Audience:** Assume the translation is for a general Chinese-speaking audience.
-                    //                 4.  **Style:** If the original Japanese text has a specific style (e.g., formal, informal, emotional, technical), try to reflect that style pobreza in the Chinese translation, while ensuring naturalness.
-                    //                 5.  **Proper Nouns and Terminology:**
-                    //                     *   For common Japanese proper nouns (names of people, places, organizations) that have established Chinese translations, use the established translation.
-                    //                     *   For less common proper nouns or specific in-game/in-universe terminology, if no standard translation exists, you may use a a transliteration (音译) or a descriptive translation (意译) that is clear and consistent. If transliterating, aim for common and recognizable Chinese characters.
-                    //                     *   Do NOT provide multiple translation options for a single term within the output. Choose the best one.
-                    //                 6.  **Handling Ambiguity:** If a Japanese phrase is ambiguous, translate it based on the most likely anpassung in the given (limited) context, aiming for a generally understandable interpretation.
-                    //                 7.  **No Extra Information:** Do NOT explain your translation choices. Do NOT ask clarifying questions. Do NOT add any disclaimers. Your entire output must be the Chinese translation.
-
-                    //                 **Example Interaction (Conceptual):**
-                    //                 *   **User (Input to you, the translation engine):** こんにちは、世界！
-                    //                 *   **You (Your Output):** 你好，世界！
-                    //                 *   **User:** あの日の約束、覚えてる？
-                    //                 *   **You:** 还记得那一天的约定吗？
-                    //                 **Your only function is to receive Japanese text and output its Simplified Chinese translation. Nothing else.**`,
-                    //         },
-                    //     });
-                    //     // fullResponse = response.text;
-                    //     // process.stdout.write(fullResponse);
-                    // }
-                    
-                    // process.stdout.write("line388");
-                    if (needScreenshot){
-                        const config_reminder = {message: "刚才我向你询问了一张图片有关：" + prompt + "。你的回答是:" + fullResponse,
-                            config: {
-                                systemInstruction: this.messages[0].content,
-                            }}
-                        const diacarded = await this.chat.sendMessage(config_reminder);
-                        process.stdout.write("reminder used");
-                        process.stdout.write(diacarded.text);
-                    }
-
-                    this.messages.push({'role': 'assistant', 'content': fullResponse});
-                    if (this.enableContextLimit) {
-                        this.trimMessages();
-                    }
-                } catch (error) {
-                        process.stdout.write("Google AI Studio error:", error);
-                        this.showSubtitle(error.message, 3000);
-                        this.asrProcessor.resumeRecording();
-                        setTimeout(() => this.hideSubtitle(), 3000);
-                }
-            }
-            else if (this.provider !== 'google_aistudio') {
-                // 如果需要截图，创建多模态消息
-                if (needScreenshot) {
-                    try {
-                        console.log("需要截图");
-                        const screenshotPath = await this.takeScreenshot();
-                        const base64Image = await this.imageToBase64(screenshotPath);
-
-                        // 创建包含图片的消息用于API请求
-                        // 找到最后一条用户消息替换为多模态消息
-                        const lastUserMsgIndex = messagesForAPI.findIndex(
-                            msg => msg.role === 'user' && msg.content === prompt
-                        );
-
-                        if (lastUserMsgIndex !== -1) {
-                            messagesForAPI[lastUserMsgIndex] = {
-                                'role': 'user',
-                                'content': [
-                                    {'type': 'text', 'text': prompt},
-                                    {'type': 'image_url', 'image_url': {'url': `data:image/jpeg;base64,${base64Image}`}}
-                                ]
-                            };
-                        }
-                    } catch (error) {
-                        console.error("截图处理失败:", error);
-                        // 如果截图失败，使用纯文本消息，已经设置好了
-                    }
-                }
-
-            // 调试消息数组
-            console.log(`发送给LLM的消息数: ${messagesForAPI.length}`);
-
-            // 发送请求到LLM
-            const response = await fetch(`${this.API_URL}/chat/completions`, {
-                method: 'POST',
-                headers: {
-                    'Content-Type': 'application/json',
-                    'Authorization': `Bearer ${this.API_KEY}`
-                },
-                body: JSON.stringify({
-                    model: this.MODEL,
-                    messages: messagesForAPI,
-                    stream: true
-                })
-            });
-
-            if (!response.ok) {
-                // 根据HTTP状态码提供具体错误信息
-                let errorMessage = "";
-                switch(response.status) {
-                    case 401:
-                        errorMessage = "API密钥验证失败，请检查你的API密钥";
-                        break;
-                    case 403:
-                        errorMessage = "API访问被禁止，你的账号可能被限制";
-                        break;
-                    case 404:
-                        errorMessage = "API接口未找到，请检查API地址";
-                        break;
-                    case 429:
-                        errorMessage = "请求过于频繁，超出API限制";
-                        break;
-                    case 500:
-                    case 502:
-                    case 503:
-                    case 504:
-                        errorMessage = "服务器错误，AI服务当前不可用";
-                        break;
-                    default:
-                        errorMessage = `API错误: ${response.status} ${response.statusText}`;
-                }
-                throw new Error(errorMessage);
-            }
-
-            const reader = response.body.getReader();
-            const decoder = new TextDecoder("utf-8");
-
-            while (true) {
-                const { value, done } = await reader.read();
-                if (done) {
-                    // 确保所有待处理文本都被发送到TTS
-                    this.ttsProcessor.finalizeStreamingText();
-                    break;
-                }
-
-                const text = decoder.decode(value);
-                const lines = text.split('\n');
-
-                for (const line of lines) {
-                    if (line.startsWith('data: ')) {
-                        if (line.includes('[DONE]')) continue;
-
-                        try {
-                            const data = JSON.parse(line.slice(6));
-                            if (data.choices[0].delta.content) {
-                                const newContent = data.choices[0].delta.content;
-                                fullResponse += newContent;
-
-                                // 将新的文本片段传递给TTS处理器进行实时处理
-                                this.ttsProcessor.addStreamingText(newContent);
-                            }
-                        } catch (e) {
-                            console.error('解析响应错误:', e);
-                        }
-                    }
-                }
-            }
-
-            if (fullResponse) {
-                // 保存原始回复（包含情绪标签）到上下文
-                this.messages.push({'role': 'assistant', 'content': fullResponse});
-
-                // 在接收响应后再次进行消息裁剪
-                if (this.enableContextLimit) {
-                    this.trimMessages();
-                }
-            }
-            }
-        } catch (error) {
-            console.error("LLM处理错误:", error);
-
-            // 检查错误类型，显示具体错误信息
-            let errorMessage = "抱歉，出现了一个错误";
-
-            if (error.message.includes("API密钥验证失败")) {
-                errorMessage = "API密钥错误，请检查配置";
-            } else if (error.message.includes("API访问被禁止")) {
-                errorMessage = "API访问受限，请联系支持";
-            } else if (error.message.includes("API接口未找到")) {
-                errorMessage = "无效的API地址，请检查配置";
-            } else if (error.message.includes("请求过于频繁")) {
-                errorMessage = "请求频率超限，请稍后再试";
-            } else if (error.message.includes("服务器错误")) {
-                errorMessage = "AI服务不可用，请稍后再试";
-            } else if (error.name === "TypeError" && error.message.includes("fetch")) {
-                errorMessage = "网络错误，请检查网络连接";
-            } else if (error.name === "SyntaxError") {
-                errorMessage = "解析API响应出错，请重试";
-            }
-
-            this.showSubtitle(errorMessage, 3000);
-            // 出错时也要解锁ASR
-            this.asrProcessor.resumeRecording();
-            // 出错时也要隐藏字幕
-            setTimeout(() => this.hideSubtitle(), 3000);
-        } finally {
-            // 确保解除处理用户输入的锁定状态
-            global.isProcessingUserInput = false;
-        }
-    }
-
-    handleTextMessage(text) {
-        // 显示用户消息
-        this.addChatMessage('user', text);
-
-        // 锁定ASR，防止语音输入干扰
-        this.asrLocked = true;
-
-        // 处理文本消息
-        this.sendToLLM(text);
-    }
-
-    addChatMessage(role, content) {
-        const chatMessages = document.getElementById('chat-messages');
-        const messageElement = document.createElement('div');
-        messageElement.innerHTML = `<strong>${role === 'user' ? '你' : 'Seraphim'}:</strong> ${content}`;
-        chatMessages.appendChild(messageElement);
-        chatMessages.scrollTop = chatMessages.scrollHeight;
-    }
-
-    // 处理弹幕消息
-    async handleBarrageMessage(nickname, text) {
-        try {
-            if (!this) return;
-
-            // 如果正在播放TTS，直接返回，不处理弹幕
-            if (global.isPlayingTTS) {
-                console.log('TTS正在播放，弹幕处理已延迟');
-                return;
-            }
-
-            // 确保系统提示已增强
-            enhanceSystemPrompt();
-
-            // 将弹幕消息添加到主对话历史中，带标记
-            this.messages.push({
-                'role': 'user',
-                'content': `[弹幕] ${nickname}: ${text}`
-            });
-
-            // 如果启用了上下文限制，需要裁剪消息
-            if (this.enableContextLimit) {
-                this.trimMessages();
-            }
-
-            // 重置TTS处理器
-            this.ttsProcessor.reset();
-
-            // 发送请求到LLM
-            const response = await fetch(`${this.API_URL}/chat/completions`, {
-                method: 'POST',
-                headers: {
-                    'Content-Type': 'application/json',
-                    'Authorization': `Bearer ${this.API_KEY}`
-                },
-                body: JSON.stringify({
-                    model: this.MODEL,
-                    messages: this.messages,
-                    stream: true
-                })
-            });
-
-            if (!response.ok) {
-                // 根据HTTP状态码提供具体错误信息
-                let errorMessage = "";
-                switch(response.status) {
-                    case 401:
-                        errorMessage = "API密钥验证失败，请检查你的API密钥";
-                        break;
-                    case 403:
-                        errorMessage = "API访问被禁止，你的账号可能被限制";
-                        break;
-                    case 404:
-                        errorMessage = "API接口未找到，请检查API地址";
-                        break;
-                    case 429:
-                        errorMessage = "请求过于频繁，超出API限制";
-                        break;
-                    case 500:
-                    case 502:
-                    case 503:
-                    case 504:
-                        errorMessage = "服务器错误，AI服务当前不可用";
-                        break;
-                    default:
-                        errorMessage = `API错误: ${response.status} ${response.statusText}`;
-                }
-                throw new Error(errorMessage);
-            }
-
-            let fullResponse = "";
-            const reader = response.body.getReader();
-            const decoder = new TextDecoder("utf-8");
-
-            while (true) {
-                const { value, done } = await reader.read();
-                if (done) {
-                    this.ttsProcessor.finalizeStreamingText();
-                    break;
-                }
-
-                const text = decoder.decode(value);
-                const lines = text.split('\n');
-
-                for (const line of lines) {
-                    if (line.startsWith('data: ')) {
-                        if (line.includes('[DONE]')) continue;
-
-                        try {
-                            const data = JSON.parse(line.slice(6));
-                            if (data.choices[0].delta.content) {
-                                const newContent = data.choices[0].delta.content;
-                                fullResponse += newContent;
-                                this.ttsProcessor.addStreamingText(newContent);
-                            }
-                        } catch (e) {
-                            console.error('解析响应错误:', e);
-                        }
-                    }
-                }
-            }
-
-            if (fullResponse) {
-                // 保存原始回复（包含情绪标签）到对话历史
-                this.messages.push({'role': 'assistant', 'content': fullResponse});
-
-                // 再次裁剪消息
-                if (this.enableContextLimit) {
-                    this.trimMessages();
-                }
-
-                // 构建要追加的弹幕对话内容 - 不包含时间戳和空行
-                const newContent = `【弹幕】[${nickname}]: ${text}\n【Seraphim】: ${fullResponse}\n`;
-
-                // 追加到对话记录文件
-                try {
-                    fs.appendFileSync(
-                        path.join(__dirname, '..', '对话记录.txt'),
-                        newContent,
-                        'utf8'
-                    );
-                } catch (error) {
-                    console.error('保存弹幕对话记录失败:', error);
-                }
-            }
-        } catch (error) {
-            console.error('处理弹幕消息出错:', error);
-
-            // 检查错误类型，显示具体错误信息
-            let errorMessage = "抱歉，处理弹幕出错";
-
-            if (error.message.includes("API密钥验证失败")) {
-                errorMessage = "API密钥错误，请检查配置";
-            } else if (error.message.includes("API访问被禁止")) {
-                errorMessage = "API访问受限，请联系支持";
-            } else if (error.message.includes("API接口未找到")) {
-                errorMessage = "无效的API地址，请检查配置";
-            } else if (error.message.includes("请求过于频繁")) {
-                errorMessage = "请求频率超限，请稍后再试";
-            } else if (error.message.includes("服务器错误")) {
-                errorMessage = "AI服务不可用，请稍后再试";
-            } else if (error.name === "TypeError" && error.message.includes("fetch")) {
-                errorMessage = "网络错误，请检查网络连接";
-            } else if (error.name === "SyntaxError") {
-                errorMessage = "解析API响应出错，请重试";
-            }
-
-            this.showSubtitle(errorMessage, 3000);
-            // 出错时解锁ASR
-            this.asrProcessor.resumeRecording();
-        }
-    }
-}
-
-module.exports = { VoiceChatInterface };
\ No newline at end of file
diff --git a/live-2d/main.js b/live-2d/main.js
deleted file mode 100644
index 90e1f84..0000000
--- a/live-2d/main.js
+++ /dev/null
@@ -1,314 +0,0 @@
-const { app, BrowserWindow, ipcMain, screen, globalShortcut, desktopCapturer, dialog } = require('electron')
-const path = require('path')
-const fs = require('fs')
-
-// 添加配置文件路径
-const configPath = path.join(app.getAppPath(), 'config.json');
-const defaultConfigPath = path.join(app.getAppPath(), 'default_config.json');
-
-// 更新Live2D模型路径的函数
-function updateLive2DModelPath() {
-    console.log('开始更新Live2D模型路径...')
-    const appDir = app.getAppPath()
-    const modelDir = path.join(appDir, '2D') // 指定模型所在的"2D"文件夹
-    
-    // 检查2D文件夹是否存在
-    if (!fs.existsSync(modelDir)) {
-        console.log('2D文件夹不存在，不进行更新')
-        return
-    }
-    
-    // 查找2D文件夹中的所有.model3.json文件
-    let modelFiles = []
-    try {
-        const files = fs.readdirSync(modelDir)
-        modelFiles = files.filter(file => file.endsWith('.model3.json'))
-        
-        if (modelFiles.length === 0) {
-            console.log('2D文件夹中没有找到.model3.json文件，不进行更新')
-            return
-        }
-        
-        // 使用第一个找到的模型文件
-        const selectedModelFile = modelFiles[0]
-        const relativeModelPath = path.join('2D', selectedModelFile).replace(/\\/g, '/') // 使用相对路径，确保使用正斜杠
-        console.log(`找到模型文件: ${relativeModelPath}`)
-        
-        // 读取并更新app.js文件
-        const appJsPath = path.join(appDir, 'app.js')
-        let jsContent = fs.readFileSync(appJsPath, 'utf8')
-        
-        // 查找并替换模型路径
-        const pattern = /const model = await PIXI\.live2d\.Live2DModel\.from\("([^"]*)"\);/
-        const replacement = `const model = await PIXI.live2d.Live2DModel.from("${relativeModelPath}");`
-        
-        if (pattern.test(jsContent)) {
-            // 替换匹配到的内容
-            jsContent = jsContent.replace(pattern, replacement)
-            
-            // 写回文件
-            fs.writeFileSync(appJsPath, jsContent, 'utf8')
-            console.log(`成功更新app.js文件中的模型路径为: ${relativeModelPath}`)
-        } else {
-            console.log('在app.js中没有找到匹配的模型加载代码行')
-        }
-    } catch (err) {
-        console.error('更新Live2D模型路径时出错:', err)
-    }
-}
-
-// 修改后的函数，不再检查配置文件是否存在
-function ensureConfigExists() {
-    // 假设配置文件一定存在，只记录一条日志
-    console.log('使用现有配置文件');
-}
-
-function ensureTopMost(win) {
-    if (!win.isAlwaysOnTop()) {
-        win.setAlwaysOnTop(true, 'screen-saver')
-    }
-}
-
-function createWindow () {
-    const primaryDisplay = screen.getPrimaryDisplay()
-    const { width: screenWidth, height: screenHeight } = primaryDisplay.workAreaSize
-    const win = new BrowserWindow({
-        width: screenWidth,
-        height: screenHeight,
-        transparent: true,
-        frame: false,
-        alwaysOnTop: true,
-        backgroundColor: '#00000000',
-        hasShadow: false,
-        focusable: true,
-        type: 'desktop',
-        webPreferences: {
-            nodeIntegration: true,
-            contextIsolation: false,
-            enableRemoteModule: true,
-            zoomFactor: 1.0,
-            enableWebSQL: true
-        },
-        resizable: true,
-        movable: true,
-        skipTaskbar: true,
-        maximizable: false,
-    })
-    win.setAlwaysOnTop(true, 'screen-saver')
-    win.setIgnoreMouseEvents(true, { forward: true });
-    win.setMenu(null)
-    win.setPosition(0, 0)
-    win.loadFile('index.html')
-    win.on('minimize', (event) => {
-        event.preventDefault()
-        win.restore()
-    })
-    win.on('will-move', (event, newBounds) => {
-        const { width, height } = primaryDisplay.workAreaSize
-        if (newBounds.x < 0 || newBounds.y < 0 || 
-            newBounds.x + newBounds.width > width || 
-            newBounds.y + newBounds.height > height) {
-            event.preventDefault()
-        }
-    })
-    win.on('blur', () => {
-        ensureTopMost(win)
-    })
-    setInterval(() => {
-        ensureTopMost(win)
-    }, 1000)
-    
-    // 为调试添加开发者工具快捷键
-    globalShortcut.register('F12', () => {
-        win.webContents.openDevTools();
-    });
-    
-    return win
-}
-
-// 在主进程启动时调用
-app.whenReady().then(() => {
-    // 确保配置文件存在（已修改，现在只打印日志）
-    ensureConfigExists();
-    
-    // 在创建窗口前先更新Live2D模型路径
-    updateLive2DModelPath();
-    
-    const mainWindow = createWindow();
-    
-    // 添加配置相关的快捷键
-    globalShortcut.register('CommandOrControl+,', () => {
-        openConfigEditor(mainWindow);
-    });
-    
-    globalShortcut.register('CommandOrControl+Q', () => {
-        app.quit();
-    });
-
-
-    // 添加打断功能的全局快捷键
-    globalShortcut.register('CommandOrControl+G', () => {
-        // 发送中断消息到渲染进程
-        const mainWindow = BrowserWindow.getAllWindows()[0];
-        if (mainWindow) {
-            mainWindow.webContents.send('interrupt-tts');
-        }
-    });
-
-
-    globalShortcut.register('CommandOrControl+T', () => {
-        const windows = BrowserWindow.getAllWindows();
-        windows.forEach(win => {
-            win.setAlwaysOnTop(true, 'screen-saver');
-        });
-    });
-});
-
-
-
-app.on('window-all-closed', () => {
-    if (process.platform !== 'darwin') {
-        app.quit()
-    }
-})
-
-app.on('activate', () => {
-    if (BrowserWindow.getAllWindows().length === 0) {
-        createWindow()
-    }
-})
-
-// 修改打开配置编辑器的功能，假设配置文件总是存在
-function openConfigEditor(parentWindow) {
-    try {
-        // 使用系统默认应用打开配置文件
-        require('electron').shell.openPath(configPath);
-    } catch (error) {
-        console.error('打开配置文件失败:', error);
-        dialog.showMessageBox(parentWindow, {
-            type: 'error',
-            title: '错误',
-            message: '无法打开配置文件',
-            detail: error.message,
-            buttons: ['确定']
-        });
-    }
-}
-
-ipcMain.on('window-move', (event, { mouseX, mouseY }) => {
-    const win = BrowserWindow.fromWebContents(event.sender)
-    const [currentX, currentY] = win.getPosition()
-    const { width: screenWidth, height: screenHeight } = screen.getPrimaryDisplay().workAreaSize
-    let newX = currentX + mouseX
-    let newY = currentY + mouseY
-    newX = Math.max(-win.getBounds().width + 100, Math.min(newX, screenWidth - 100))
-    newY = Math.max(-win.getBounds().height + 100, Math.min(newY, screenHeight - 100))
-    win.setPosition(newX, newY)
-})
-
-ipcMain.on('set-ignore-mouse-events', (event, { ignore, options }) => {
-    BrowserWindow.fromWebContents(event.sender).setIgnoreMouseEvents(ignore, options)
-})
-
-ipcMain.on('request-top-most', (event) => {
-    const win = BrowserWindow.fromWebContents(event.sender)
-    win.setAlwaysOnTop(true, 'screen-saver')
-})
-
-// 添加保存配置的IPC处理器
-ipcMain.handle('save-config', async (event, configData) => {
-    try {
-        // 创建备份
-        if (fs.existsSync(configPath)) {
-            const backupPath = `${configPath}.bak`;
-            fs.copyFileSync(configPath, backupPath);
-        }
-        
-        // 保存新配置
-        fs.writeFileSync(configPath, JSON.stringify(configData, null, 2), 'utf8');
-        
-        // 通知用户需要重启应用
-        const result = await dialog.showMessageBox({
-            type: 'info',
-            title: '配置已保存',
-            message: '配置已成功保存',
-            detail: '需要重启应用以应用新配置。现在重启应用吗？',
-            buttons: ['是', '否'],
-            defaultId: 0
-        });
-        
-        // 如果用户选择重启
-        if (result.response === 0) {
-            app.relaunch();
-            app.exit();
-        }
-        
-        return { success: true };
-    } catch (error) {
-        console.error('保存配置失败:', error);
-        return { success: false, error: error.message };
-    }
-});
-
-// 修改获取配置的IPC处理器，假设配置文件总是存在
-ipcMain.handle('get-config', async (event) => {
-    try {
-        const configData = fs.readFileSync(configPath, 'utf8');
-        return { success: true, config: JSON.parse(configData) };
-    } catch (error) {
-        console.error('获取配置失败:', error);
-        return { success: false, error: error.message };
-    }
-});
-
-// 添加打开配置文件的IPC处理器
-ipcMain.handle('open-config-editor', async (event) => {
-    const win = BrowserWindow.fromWebContents(event.sender);
-    openConfigEditor(win);
-    return { success: true };
-});
-
-// 修改后的截图功能：不再隐藏窗口
-ipcMain.handle('take-screenshot', async (event, outputPath) => {
-    try {
-        // 获取所有屏幕源
-        const sources = await desktopCapturer.getSources({ 
-            types: ['screen'],
-            thumbnailSize: screen.getPrimaryDisplay().workAreaSize
-        })
-        
-        // 通常选择第一个屏幕（主屏幕）
-        const primaryScreen = sources[0]
-        
-        // 确保输出目录存在
-        const outputDir = path.dirname(outputPath)
-        if (!fs.existsSync(outputDir)) {
-            fs.mkdirSync(outputDir, { recursive: true })
-        }
-        
-        // 将NativeImage转换为PNG并保存
-        fs.writeFileSync(outputPath, primaryScreen.thumbnail.toJPEG(75)); // 75是图片的质量参数，可以调整
-        
-        return outputPath
-    } catch (error) {
-        console.error('截图错误:', error)
-        throw error
-    }
-})
-
-// 添加IPC处理器，允许从渲染进程手动更新模型
-ipcMain.handle('update-live2d-model', async (event) => {
-    try {
-        // 调用更新模型的函数
-        updateLive2DModelPath()
-        
-        // 通知渲染进程需要重新加载以应用新模型
-        const win = BrowserWindow.fromWebContents(event.sender)
-        win.reload()
-        
-        return { success: true, message: '模型已更新，页面将重新加载' }
-    } catch (error) {
-        console.error('手动更新模型时出错:', error)
-        return { success: false, message: `更新失败: ${error.message}` }
-    }
-})
\ No newline at end of file
diff --git a/live-2d/package.json b/live-2d/package.json
deleted file mode 100644
index 0a2bf25..0000000
--- a/live-2d/package.json
+++ /dev/null
@@ -1,21 +0,0 @@
-{
-  "name": "combined-project",
-  "version": "1.0.0",
-  "description": "Combined Project",
-  "main": "main.js",
-  "scripts": {
-    "start": "electron .",
-    "start-server": "node server.js"
-  },
-  "dependencies": {
-    "axios": "^1.9.0",
-    "cors": "^2.8.5",
-    "electron": "^28.0.0",
-    "express": "^5.1.0",
-    "pixi-live2d-display": "^0.3.1",
-    "pixi.js": "^6.5.2"
-  },
-  "keywords": [],
-  "author": "",
-  "license": "ISC"
-}
diff --git a/live-2d/server-tools/recordServer.js b/live-2d/server-tools/recordServer.js
deleted file mode 100644
index cd16e16..0000000
--- a/live-2d/server-tools/recordServer.js
+++ /dev/null
@@ -1,162 +0,0 @@
-// recordServer.js - 带原文的记录工具 (合并版)
-
-const fs = require('fs');
-const path = require('path');
-
-// 文件路径 - 保存在上一级目录
-const RECORDS_FILE = path.join(process.cwd(), '..', 'text_database.txt');
-
-// 工具定义 - 重要信息记录
-const NOTE_TOOL = {
-    name: "record_note",
-    description: "记录用户要求的信息到文件中，当用户要求记录某些内容时，使用此工具记录",
-    parameters: {
-        type: "object",
-        properties: {
-            content: {
-                type: "string",
-                description: "要记录的内容"
-            }
-        },
-        required: ["content"]
-    }
-};
-
-// 工具定义 - 情感关怀记录 (带原文)
-const CARE_TOOL = {
-    name: "record_emotional_insight",
-    description: "记录用户情感状态的洞察和总结。当用户分享个人情感问题、心理困扰或成长挑战时使用。",
-    parameters: {
-        type: "object",
-        properties: {
-            user_message: {
-                type: "string",
-                description: "用户的原始消息内容"
-            },
-            summary: {
-                type: "string",
-                description: "对用户情感状态的总结，以及自己对用户吐露这些内容的想法。要用自己的性格来关怀用户并给出自己的点评和想法"
-            }
-        },
-        required: ["user_message", "summary"]
-    }
-};
-
-// 获取简化的日期 (只到天)
-function getSimpleDate() {
-    const now = new Date();
-    const year = now.getFullYear();
-    const month = now.getMonth() + 1;
-    const day = now.getDate();
-    return `${year}年${month}月${day}日`;
-}
-
-// 保存重要信息到文件
-async function saveNote(content) {
-    try {
-        // 获取简化日期
-        const date = getSimpleDate();
-        
-        // 格式化笔记
-        const note = `[${date}] 普通记录: ${content}\n\n`;
-        
-        // 检查文件是否存在，不存在则创建
-        if (!fs.existsSync(RECORDS_FILE)) {
-            fs.writeFileSync(RECORDS_FILE, '', 'utf8');
-        }
-        
-        // 追加笔记到文件
-        fs.appendFileSync(RECORDS_FILE, note, 'utf8');
-        
-        return {
-            success: true,
-            file: RECORDS_FILE
-        };
-    } catch (error) {
-        console.error('保存笔记错误:', error);
-        throw error;
-    }
-}
-
-// 保存关怀记录到文件 (带原文)
-async function saveCareRecord(userMessage, summary) {
-    try {
-        // 获取简化日期
-        const date = getSimpleDate();
-        
-        // 格式化记录，包含用户原文
-        const record = `[${date}] 情感记录:\n用户原文: "${userMessage}"\n总结: ${summary}\n\n`;
-        
-        // 检查文件是否存在，不存在则创建
-        if (!fs.existsSync(RECORDS_FILE)) {
-            fs.writeFileSync(RECORDS_FILE, '', 'utf8');
-        }
-        
-        // 追加记录到文件
-        fs.appendFileSync(RECORDS_FILE, record, 'utf8');
-        
-        return {
-            success: true,
-            file: RECORDS_FILE
-        };
-    } catch (error) {
-        console.error('保存情感记录错误:', error);
-        throw error;
-    }
-}
-
-// 模块接口：获取工具定义
-function getToolDefinitions() {
-    return [NOTE_TOOL, CARE_TOOL];
-}
-
-// 模块接口：执行工具函数
-async function executeFunction(name, parameters) {
-    // 处理重要信息记录
-    if (name === "record_note") {
-        const content = parameters?.content;
-        if (!content || content.trim() === '') {
-            throw new Error("记录内容不能为空");
-        }
-        
-        try {
-            await saveNote(content);
-            return `✅ 已记录到all_records.txt文件`;
-        } catch (error) {
-            return `⚠️ 记录失败: ${error.message}`;
-        }
-    }
-    
-    // 处理情感关怀记录
-    else if (name === "record_emotional_insight") {
-        const userMessage = parameters?.user_message;
-        const summary = parameters?.summary;
-        
-        if (!userMessage || userMessage.trim() === '') {
-            throw new Error("用户原文不能为空");
-        }
-        
-        if (!summary || summary.trim() === '') {
-            throw new Error("情感总结不能为空");
-        }
-        
-        try {
-            await saveCareRecord(userMessage, summary);
-            // 这个工具应该是"静默"的，不直接告诉用户记录了什么
-            return `✓ 记录已保存`; // 这个返回值通常不会直接展示给用户
-        } catch (error) {
-            return `⚠️ 情感记录失败: ${error.message}`;
-        }
-    }
-    
-    // 未知工具
-    else {
-        throw new Error(`此模块不支持工具: ${name}`);
-    }
-}
-
-// 导出模块接口
-module.exports = {
-    getToolDefinitions,
-    executeFunction
-};
\ No newline at end of file
diff --git a/live-2d/server-tools/searchServer.js b/live-2d/server-tools/searchServer.js
deleted file mode 100644
index f8e5f8f..0000000
--- a/live-2d/server-tools/searchServer.js
+++ /dev/null
@@ -1,106 +0,0 @@
-// searchServer.js - 只返回内容的搜索工具
-const axios = require('axios');
-
-// Tavily API配置
-const TAVILY_API_KEY = "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";
-
-// 工具定义
-const SEARCH_TOOL = {
-    name: "web_search",
-    description: "使用搜索网络引擎，并返回内容",
-    parameters: {
-        type: "object",
-        properties: {
-            query: {
-                type: "string",
-                description: "搜索关键词"
-            },
-            max_results: {
-                type: "number",
-                description: "最大返回结果数量",
-                default: 1
-            },
-            max_chars: {
-                type: "number",
-                description: "每个结果最大提取的字符数",
-                default: 5000
-            }
-        },
-        required: ["query"]
-    }
-};
-
-// 搜索功能实现 - 只返回内容
-async function searchWebContentOnly(query, maxResults = 1, maxChars = 5000) {
-    try {
-        console.log(`正在搜索: ${query}`);
-        
-        // 搜索获取URL
-        const searchResponse = await axios.post("https://api.tavily.com/search", {
-            query: query,
-            max_results: maxResults,
-            api_key: TAVILY_API_KEY
-        });
-        
-        const urls = searchResponse.data.results.map(result => result.url);
-        
-        if (urls.length === 0) {
-            return `未找到关于 "${query}" 的搜索结果`;
-        }
-        
-        console.log(`找到 ${urls.length} 个结果，正在提取内容...`);
-        
-        // 提取内容
-        const extractResponse = await axios.post("https://api.tavily.com/extract", {
-            urls: urls,
-            api_key: TAVILY_API_KEY
-        });
-        
-        // 只提取内容，不包括链接和其他元数据
-        let allContent = "";
-        
-        extractResponse.data.results.forEach(item => {
-            const content = item.raw_content || '';
-            
-            // 只保留maxChars长度的内容
-            if (content.length > maxChars) {
-                allContent += content.substring(0, maxChars) + "\n\n";
-            } else {
-                allContent += content + "\n\n";
-            }
-        });
-        
-        return allContent.trim();
-    } catch (error) {
-        console.error("搜索错误:", error.message);
-        if (error.response) {
-            console.error(`状态码: ${error.response.status}`);
-        }
-        return `搜索失败: ${error.message}`;
-    }
-}
-
-// MCP模块接口
-module.exports = {
-    // 获取工具定义
-    getToolDefinitions: function() {
-        return [SEARCH_TOOL];
-    },
-    
-    // 执行工具函数
-    executeFunction: async function(name, parameters) {
-        if (name !== "web_search") {
-            throw new Error(`不支持的函数: ${name}`);
-        }
-        
-        const query = parameters.query;
-        if (!query) {
-            throw new Error("缺少搜索关键词");
-        }
-        
-        const maxResults = parameters.max_results || 1;
-        const maxChars = parameters.max_chars || 5000;
-        
-        return await searchWebContentOnly(query, maxResults, maxChars);
-    }
-};
\ No newline at end of file
diff --git a/live-2d/server-tools/server.js b/live-2d/server-tools/server.js
deleted file mode 100644
index 20ee62a..0000000
--- a/live-2d/server-tools/server.js
+++ /dev/null
@@ -1,332 +0,0 @@
-// server.js - 主MCP服务器
-// 自动加载所有子模块的版本
-
-const express = require('express');
-const cors = require('cors');
-const fs = require('fs');
-const path = require('path');
-const app = express();
-const PORT = 3000;
-
-// 启用CORS和JSON解析
-app.use(cors());
-app.use(express.json());
-
-// 存储SSE客户端连接
-const sseClients = {};
-
-// 存储所有加载的模块
-let modules = [];
-// 汇总所有工具定义
-let allTools = [];
-
-// 动态加载所有JavaScript文件作为模块
-function loadModules() {
-    modules = [];
-    allTools = [];
-    
-    // 读取当前目录中所有文件
-    const files = fs.readdirSync(__dirname);
-    
-    // 处理每个JavaScript文件
-    files.forEach(file => {
-        // 跳过主服务器文件和非JavaScript文件
-        if (file === 'server.js' || !file.endsWith('.js')) {
-            return;
-        }
-        
-        try {
-            const modulePath = path.join(__dirname, file);
-            const module = require(modulePath);
-            
-            // 检查模块是否有必要的接口
-            if (typeof module.getToolDefinitions === 'function' && 
-                typeof module.executeFunction === 'function') {
-                modules.push(module);
-                
-                // 获取并添加工具定义
-                const tools = module.getToolDefinitions();
-                if (Array.isArray(tools) && tools.length > 0) {
-                    allTools = [...allTools, ...tools];
-                    console.log(`已加载模块: ${file} (${tools.length}个工具)`);
-                } else {
-                    console.warn(`模块 ${file} 没有返回有效的工具定义`);
-                }
-            } else {
-                console.warn(`跳过文件 ${file}: 不是有效的MCP模块(缺少必要的接口)`);
-            }
-        } catch (error) {
-            console.error(`加载模块 ${file} 失败:`, error);
-        }
-    });
-    
-    console.log(`总共加载了 ${modules.length} 个模块, ${allTools.length} 个工具`);
-}
-
-// 查找工具对应的模块
-function findModuleForTool(toolName) {
-    return modules.find(module => 
-        module.getToolDefinitions().some(tool => tool.name === toolName)
-    );
-}
-
-// MCP发现端点 - 符合标准MCP规范
-app.post('/mcp/v1/discover', (req, res) => {
-    // MCP发现响应
-    const serverInfo = {
-        // MCP服务器信息
-        server: {
-            name: "自动加载MCP服务器",
-            version: "1.0.0",
-            vendor: "演示应用",
-            description: "自动加载所有模块的MCP服务器"
-        },
-        // 可用工具（功能）列表
-        functions: allTools
-    };
-
-    res.json(serverInfo);
-});
-
-// MCP调用端点 - 符合标准MCP规范
-app.post('/mcp/v1/invoke', async (req, res) => {
-    const { name, parameters } = req.body;
-
-    if (!name) {
-        return res.status(400).json({
-            error: {
-                message: "缺少函数名称",
-                type: "InvalidRequest"
-            }
-        });
-    }
-
-    // 查找负责处理该工具的模块
-    const module = findModuleForTool(name);
-    if (!module) {
-        return res.status(404).json({
-            error: {
-                message: `未知函数: ${name}`,
-                type: "UnknownFunction"
-            }
-        });
-    }
-
-    try {
-        // 委托给对应模块处理
-        const result = await module.executeFunction(name, parameters);
-
-        // 返回MCP标准格式的调用结果
-        res.json({
-            result: {
-                content: result
-            }
-        });
-    } catch (error) {
-        res.status(500).json({
-            error: {
-                message: `函数执行失败: ${error.message}`,
-                type: "ExecutionError"
-            }
-        });
-    }
-});
-
-// 重新加载模块端点 - 允许在不重启服务器的情况下重新加载模块
-app.post('/reload', (req, res) => {
-    try {
-        loadModules();
-        res.json({
-            success: true,
-            modules: modules.length,
-            tools: allTools.map(tool => tool.name)
-        });
-    } catch (error) {
-        res.status(500).json({
-            error: error.message
-        });
-    }
-});
-
-// 健康检查端点
-app.get('/health', (req, res) => {
-    res.json({ 
-        status: 'ok',
-        modules: modules.length,
-        tools: allTools.map(tool => ({
-            name: tool.name,
-            description: tool.description
-        }))
-    });
-});
-
-// ===== SSE支持 =====
-
-// SSE连接端点
-app.get('/sse', (req, res) => {
-    // 设置SSE必要的头信息
-    res.setHeader('Content-Type', 'text/event-stream');
-    res.setHeader('Cache-Control', 'no-cache');
-    res.setHeader('Connection', 'keep-alive');
-    res.setHeader('Access-Control-Allow-Origin', '*');
-
-    // 客户端ID，使用session_id参数或生成新ID
-    const clientId = req.query.session_id || `client-${Date.now()}`;
-
-    // 发送初始连接消息
-    res.write(`event: connected\ndata: {"message": "SSE连接已建立", "clientId": "${clientId}"}\n\n`);
-
-    // 发送端点事件(MCP协议要求)
-    res.write(`event: endpoint\ndata: ${JSON.stringify({
-        endpoint: `/messages?session_id=${clientId}`
-    })}\n\n`);
-
-    // 保存连接
-    sseClients[clientId] = res;
-    console.log(`SSE客户端 ${clientId} 已连接`);
-
-    // 设置连接关闭时的处理
-    req.on('close', () => {
-        delete sseClients[clientId];
-        console.log(`SSE客户端 ${clientId} 已断开连接`);
-    });
-
-    // 发送定期保活消息
-    const keepAliveInterval = setInterval(() => {
-        if (sseClients[clientId]) {
-            res.write(`:keepalive\n\n`);
-        } else {
-            clearInterval(keepAliveInterval);
-        }
-    }, 30000); // 每30秒发送一次
-});
-
-// SSE消息处理端点
-app.post('/messages', express.json(), async (req, res) => {
-    const sessionId = req.query.session_id;
-    const messageId = req.body.id;
-    const method = req.body.method;
-    const params = req.body.params;
-
-    // 验证会话ID
-    if (!sessionId || !sseClients[sessionId]) {
-        return res.status(404).json({
-            jsonrpc: "2.0",
-            id: messageId,
-            error: {
-                code: -32001,
-                message: "无效的会话ID"
-            }
-        });
-    }
-
-    // 处理初始化请求
-    if (method === "initialize") {
-        return res.json({
-            jsonrpc: "2.0",
-            id: messageId,
-            result: {
-                capabilities: {
-                    tools: true,
-                    resources: false,
-                    prompts: false
-                }
-            }
-        });
-    }
-
-    // 处理工具列表请求
-    if (method === "tools/list") {
-        return res.json({
-            jsonrpc: "2.0",
-            id: messageId,
-            result: {
-                tools: allTools
-            }
-        });
-    }
-
-    // 处理功能列表请求
-    if (method === "listOfferings") {
-        return res.json({
-            jsonrpc: "2.0",
-            id: messageId,
-            result: {
-                resources: [],
-                tools: allTools,
-                prompts: []
-            }
-        });
-    }
-
-    // 处理工具调用
-    if (method === "tools/call") {
-        const toolName = params.name;
-        const toolArgs = params.parameters || {};
-
-        // 查找负责处理该工具的模块
-        const module = findModuleForTool(toolName);
-        if (!module) {
-            return res.status(404).json({
-                jsonrpc: "2.0",
-                id: messageId,
-                error: {
-                    code: -32601,
-                    message: `未知工具: ${toolName}`
-                }
-            });
-        }
-
-        try {
-            // 委托给对应模块处理
-            const result = await module.executeFunction(toolName, toolArgs);
-
-            // 返回工具调用结果
-            return res.json({
-                jsonrpc: "2.0",
-                id: messageId,
-                result: {
-                    content: result
-                }
-            });
-        } catch (error) {
-            console.error(`工具调用错误 ${toolName}:`, error);
-            return res.status(500).json({
-                jsonrpc: "2.0",
-                id: messageId,
-                error: {
-                    code: -32603,
-                    message: `工具执行失败: ${error.message}`
-                }
-            });
-        }
-    }
-
-    // 处理其他未知请求
-    return res.status(404).json({
-        jsonrpc: "2.0",
-        id: messageId,
-        error: {
-            code: -32601,
-            message: `未知方法: ${method}`
-        }
-    });
-});
-
-// 在服务器启动前先加载所有模块
-loadModules();
-
-// 启动服务器
-app.listen(PORT, () => {
-    console.log(`MCP服务器启动成功，监听端口: ${PORT}`);
-    console.log(`已加载的工具:`);
-    allTools.forEach(tool => {
-        console.log(`- ${tool.name}: ${tool.description}`);
-    });
-    console.log(`\n标准MCP端点:`);
-    console.log(`- http://localhost:${PORT}/mcp/v1/discover (POST)`);
-    console.log(`- http://localhost:${PORT}/mcp/v1/invoke (POST)`);
-    console.log(`\n管理端点:`);
-    console.log(`- http://localhost:${PORT}/health (GET) - 检查服务器状态`);
-    console.log(`- http://localhost:${PORT}/reload (POST) - 重新加载模块`);
-});
\ No newline at end of file
diff --git "a/live-2d/server-tools/server\346\225\231\347\250\213\350\256\262\350\247\243.txt" "b/live-2d/server-tools/server\346\225\231\347\250\213\350\256\262\350\247\243.txt"
deleted file mode 100644
index 6fb9234..0000000
--- "a/live-2d/server-tools/server\346\225\231\347\250\213\350\256\262\350\247\243.txt"
+++ /dev/null
@@ -1,136 +0,0 @@
-
-《MCP服务器功能扩展指南》（小白版）
-
-Q:什么是MCP？
-A:MCP 是claude的那个公司开源的一种协议标准，可以连接AI与外部数据源和工具。提供了连接标准化方式。
-因为以前想要让LLM使用工具，每一家都有各自的工具格式，大家都各井水不犯河水。你一种格式我一种格式。写了一个工具，可能qwen的可以用。
-glm的就不能用了。还得重新给glm写一个属于它的工具格式代码。所以mcp可以理解为统一了各家外部工具和数据的一种标准。只要是支持mcp的LLM模型，就能使用mcp编写的工具及数据等。
-
-Q:什么是MCP服务器模块？
-A:MCP服务器模块是一个JavaScript文件，它让你可以给支持mcp的LLM模型，例如claude、chatgpt、deepseek（或其他AI助手）添加使用工具的能力。
-简单来说：通过添加新模块，你可以让AI做更多事情，比如查询天气、联网搜索、控制电脑等。
-
-Q:添加新模块能做什么？
-A:每个模块都给AI添加一个或多个"工具"。每个工具让AI能执行一个特定功能。例如：
-
-1查询日期时间
-2搜索网页信息
-3控制智能家居设备
-4爬虫数据
-5翻译文本
-6使用APP
-7发送邮件/短信
-8操作数据库
-...几乎支持任何你能用代码实现的功能！
-
-Q:为什么要添加新模块？
-A:个性化功能：添加你特别需要的功能
-自动化任务：让AI帮你完成重复性工作
-连接外部服务：让AI能访问其他网站和服务
-增强AI能力：让LLM做能做更多以前做不到的事
-
-Q:如何添加新模块？
-A:创建一个新的JavaScript文件（例如：yourToolServer.js）
-编写代码实现你想要的功能
-放到当前的目录下，重启服务器
-
-服务器会自动发现并加载你的新功能，然后AI就可以使用它了！
-示例：
-想让AI查询城市空气质量？
-创建一个airQualityServer.js文件：
-javascript// 定义工具
-const AIR_TOOL = {
-    name: "check_air_quality",
-    description: "查询指定城市的空气质量指数",
-    parameters: {
-        type: "object",
-        properties: {
-            city: {
-                type: "string",
-                description: "城市名称（英文）"
-            }
-        },
-        required: ["city"]
-    }
-};
-
-// 执行工具的函数
-async function getAirQuality(parameters) {
-    const city = parameters.city;
-    // 这里写代码查询空气质量API
-    // ...
-
-    // 返回结果
-    return `${city}的空气质量：良好，AQI: 42`;
-}
-
-// 导出必要函数
-module.exports = {
-    getToolDefinitions: () => [AIR_TOOL],
-    executeFunction: async (name, parameters) => {
-        if (name !== "check_air_quality") {
-            throw new Error(`不支持此功能: ${name}`);
-        }
-        return await getAirQuality(parameters);
-    }
-};
-
-Q:不会编程怎么办？
-A:如果你不懂编程，可以：
-
-1:把这个文章全文复制发给Claude或其他AI，说出你的需求，让AI来帮你写模块代码
-2找懂编程的朋友帮忙
-3给魔方打钱，让它来给你写一个
-
-我个人比较推荐3
-
-
-小贴士：
-
-每个模块尽量专注于一个功能领域
-模块名称最好能描述其功能（如weatherServer.js）
-添加新模块后，可以访问http://localhost:3000/health查看是否加载成功，或者和AI对话测试看看AI是否能成功执行你给他定制的功能。
-
-
-
-具体格式示范：
-创建新JS文件：比如 yourToolServer.js
-基本格式：
-
-javascript// 定义工具
-const YOUR_TOOL = {
-    name: "your_tool_name", 
-    description: "简单描述",
-    parameters: {
-        type: "object",
-        properties: {
-            param1: {
-                type: "string",
-                description: "参数1说明"
-            }
-        },
-        required: ["param1"] 
-    }
-};
-
-// 执行工具的函数
-async function doYourThing(parameters) {
-    // 你的代码逻辑
-    return "返回结果";
-}
-
-// 必须导出这两个函数
-module.exports = {
-    // 返回工具定义
-    getToolDefinitions: () => [YOUR_TOOL],
-    
-    // 执行工具
-    executeFunction: async (name, parameters) => {
-        if (name !== "your_tool_name") {
-            throw new Error(`不支持: ${name}`);
-        }
-        return await doYourThing(parameters);
-    }
-};
-
-
diff --git a/live-2d/server-tools/start_server.bat b/live-2d/server-tools/start_server.bat
deleted file mode 100644
index 059588e..0000000
--- a/live-2d/server-tools/start_server.bat
+++ /dev/null
@@ -1,6 +0,0 @@
-@echo off
-cd /d %~dp0
-echo MCP...
-"..\node\node.exe" server.js
-if %ERRORLEVEL% NEQ 0 pause
-exit
diff --git a/live-2d/server-tools/voiceServer.js b/live-2d/server-tools/voiceServer.js
deleted file mode 100644
index dc10dba..0000000
--- a/live-2d/server-tools/voiceServer.js
+++ /dev/null
@@ -1,81 +0,0 @@
-// modules/voiceModule.js - 声线切换工具模块
-
-const axios = require('axios');
-
-// TTS 声线切换 API 配置
-const TTS_SERVER_BASE = "http://127.0.0.1:5000";
-const VOICE_MAP = {
-    "肥牛": 0,
-    "邪牛": 1
-};
-
-// 工具定义
-const VOICE_TOOL = {
-    name: "change_voice",
-    description: "切换TTS语音合成的声线。",
-    parameters: {
-        type: "object",
-        properties: {
-            voice_name: {
-                type: "string",
-                description: "声线名称，可选值为：肥牛、邪牛"
-            }
-        },
-        required: ["voice_name"]
-    }
-};
-
-// 切换TTS声线
-async function changeVoice(voiceName) {
-    if (!VOICE_MAP.hasOwnProperty(voiceName)) {
-        return `⚠️ 未知声线: ${voiceName}，可用声线: ${Object.keys(VOICE_MAP).join(", ")}`;
-    }
-
-    const voiceId = VOICE_MAP[voiceName];
-    const url = `${TTS_SERVER_BASE}/select_voice/${voiceId}`;
-
-    try {
-        const response = await axios.get(url, { timeout: 5000 });
-
-        if (response.status >= 200 && response.status < 300) {
-            return `✅ 已成功切换到${voiceName}的声线`;
-        } else {
-            return `⚠️ 声线切换失败，HTTP状态码: ${response.status}`;
-        }
-    } catch (error) {
-        console.error("声线切换错误:", error);
-
-        if (error.response) {
-            return `⚠️ 声线切换失败，HTTP状态码: ${error.response.status}`;
-        } else if (error.request) {
-            return "⚠️ 声线切换请求超时，TTS服务器可能未运行。";
-        } else {
-            return `⚠️ 声线切换请求失败: ${error.message}`;
-        }
-    }
-}
-
-// 模块接口：获取工具定义
-function getToolDefinitions() {
-    return [VOICE_TOOL];
-}
-
-// 模块接口：执行工具函数
-async function executeFunction(name, parameters) {
-    if (name !== "change_voice") {
-        throw new Error(`此模块不支持工具: ${name}`);
-    }
-
-    const voiceName = parameters?.voice_name;
-    if (!voiceName) {
-        throw new Error("缺少声线名称参数");
-    }
-
-    return await changeVoice(voiceName);
-}
-
-// 导出模块接口
-module.exports = {
-    getToolDefinitions,
-    executeFunction
-};
\ No newline at end of file
diff --git "a/live-2d/\346\225\231\347\250\213.txt" "b/live-2d/\346\225\231\347\250\213.txt"
deleted file mode 100644
index e0b31e6..0000000
--- "a/live-2d/\346\225\231\347\250\213.txt"
+++ /dev/null
@@ -1,117 +0,0 @@
-《MCP功能》
-
-如果你想要用联网搜索功能、记录日程、查天气。自定义工具等功能。可以在肥牛.exe里面
-在启动标签下面，左上角把”启动MCP功能“这个选项选上。然后点击右下角的保存配置。
-最后点击启动桌宠，这样就相当于打开mcp功能。则可以让肥牛使用上工具了
-
-
-《打断功能》
-
-如果不想听肥牛喋喋不休说个不停，可以使用在肥牛说话的时候按住键盘的：ctrl+G 组合按键打断肥牛说话
-但是此功能还是不是特别完善。打断后还是会多说几个字的内容。后续会跟进修复
-
-《一键替换模型皮套》
-
-当前的live 2d 皮套模型放在2D文件夹内。默认是肥牛模型（桃濑日和）
-如果想要替换live 2d模型皮套，可将"2D"文件夹里面的模型全部删除，然后粘贴为你自己的live 2d模型进去
-最后运行go.bat 
-系统会自动识别，无需担心。
-
-如果觉得默认的也挺好，那就挺好。
-
-
-text_database.txt文件是你的记忆数据库，你和模型交流后的记忆回储存在
-这个地方，也可以手动增加，或者删除。聊天的时候系统回自动判断什么时候
-记录你的内容，例如你可能说一些：帮我记录一下，明天我要去看电影、我觉得我很焦虑，感觉对未来迷茫。
-等等这种内容。可能会被记录到数据库。这些数据库里面的内容，模型会永久记住。
-
-《打字输入》
-
-双击打开："肥牛UI.exe"
-点击上方的”开场白“选框
-然后点击"显示对话框"选项
-最后点击保存配置。即可出现文字框。可在文字框内打字交流。无需启动ASR也能和模型对话。
-
-ps:感谢群友空白对此功能接入
-
-
-《哔哩哔哩直播》
-
-打开配置文件：config.json
-
-最下面的bilibili标签
-修改"roomId": "B站直播房间号" 把里面的：B站直播房间号 改为你自己的直播房间ID
-例如我"自负的魔方"直播ID是30230160
-那这里就是
-"roomId": "30230160"
-改好保存。然后直接运行go.bat 即可接入B站直播。弹幕发送的最新消息会被模型接收。
-同时依旧可以同时和模型语音对话聊天。模型也能区分弹幕和你两者的区别。
-
-《主动对话V1》
-
-此版本的主动对话功能是最基础版本。通过静默时间来控制。默认超过一分钟用户未和模型说话，且tts和
-asr这些都未触发。满足这几个条件后。即触发主动对话机制。模型会自动根据上下文来主动询问或者找话题等主动
-和你进行聊天。
-如果在静默时间范围内和模型对话。会刷新静默时间。重新记时。
-
-主动对话功能默认关闭，标签"auto_chat"
-下面的参数："enabled": false 则为启动/关闭选项
-想要开启则改为true  
-其中"idle_time": 60000
-则是静默时间。值为60000ms(毫秒) 也就是60秒
-可自行修改静默时间
-
-ps:这个版本的主动对话功能比较的基础。过于死板固定了。理论上我们人与人之间的交谈不会是一来一回的
-回合式对话。但是也不是固定一个时间点回对方一句话。而是自己想到了什么。或者对方哪句话触动
-到了自己的内心。引起了共鸣。才会想要主动多说几句。
-举个例子。如果对方说了一些你感兴趣的话题。例如AI话题或者喜欢的动漫、游戏等。
-这个情况下很有可能会触发你自己的“主动对话”
-所以。这才是正确的触发方向。后续的主动对话如果没有更让人眼前一亮的处理办法。
-则按照此逻辑开发。
-
-
-
-----------------------------------------------------------------------------------------
-
-开发者教程（非开发人员请忽略）
-
-Q：为什么模型无法同时循环播放待机动作，然后正常张口闭口？
-A：因为待机动画会和张口闭口动画冲突。需要去Hiyori.model3.json文件里面先禁止或者说删除所有的待机动画，才能自由控制张嘴闭嘴动画。
-
-详解：
-
-live 2d皮套配置文件，也就是2D文件夹里面的所有文件
-其中 Hiyori.model3.json 是肥牛的基本参数配置，默认动作都会在这里修改。
-Motions标签里面的Idle内，File后面就是模型的默认动作，默认动作是1号动作。其余还有9个动作，动作都在motions文件夹里面
-在motions文件夹内储存着各种情绪动作。但是由于这些动作都默认绑定了嘴部的参数，导致接入tts的时候，嘴巴无法开合，所以
-我把这些动作配置文件都做了修改，删除了里面所有的嘴部动作。具体来说是删除了ParamMouthForm、ParamMouthOpenY 的配置列表。
-其中，删除这些后，还得在最开头的Meta标签内，CurveCoun子标签内修改还剩下的绑定参数。CurveCoun的意思就是文件中全部的肢体绑定参数。
-因为删除了两个绑定参数（口型绑定）所以需要减去两个。例如CurveCoun本来是值是33，删除了两个后，就改成31
-
-里面我依旧保留了原版的配置参数。后面带原版的就是没有做过任何处理的配置文件。
-
-
-
-
-1.基于PYQT的打包UI
-
-UI.py 更新好后。直接运行：
-pyinstaller --onefile --windowed main.py
-
-更好的打包指令：
-pyinstaller --onedir --windowed --name="肥牛UI" main.py
-
-ps:没有安装依赖记得安装：
-pip install pyinstaller
-pip install PyQt5
-
-
-
-
-
-
-
-
-
-
-
diff --git a/neural_deploy.py b/neural_deploy.py
index d125796..dd53bfb 100644
--- a/neural_deploy.py
+++ b/neural_deploy.py
@@ -221,7 +221,7 @@ def download_live2d_model():
     """下载并解压Live 2D模型"""
     print("\n========== 下载Live 2D模型 ==========")
     # GitHub文件下载链接
-    url = "https://github.com/morettt/my-neuro/releases/download/v4.4.3/live-2d.zip"
+    url = "https://github.com/morettt/my-neuro/releases/download/v4.4.5/live-2d.zip"
     # 获取文件名
     file_name = url.split('/')[-1]
     
diff --git a/py-my-neuro/lipsync.py b/py-my-neuro/lipsync.py
new file mode 100644
index 0000000..7b6dc63
--- /dev/null
+++ b/py-my-neuro/lipsync.py
@@ -0,0 +1,98 @@
+import numpy as np
+import struct
+import time
+
+class WavHandler:
+    def __init__(self):
+        # 每个通道的采样帧数
+        self.numFrames: int = 0
+        # 采样率，帧/秒
+        self.sampleRate: int = 0
+        self.sampleWidth: int = 0
+        # 数据
+        self.pcmData: np.ndarray = None
+        # 已经读取的帧数
+        self.lastOffset: int = 0
+        # 当前rms值
+        self.currentRms: float = 0
+        # 开始读取的时间
+        self.startTime: float = -1
+        # 原始音频字节数据缓存
+        self.rawBytes: bytes = b''
+
+    def Start(self, data:dict) -> None:
+        self.ReleasePcmData()
+        try:
+            self.numFrames = data.get('num_frames')
+            self.sampleRate = data.get('framerate')
+            self.sampleWidth = data.get('sample_width')
+            self.numChannels = data.get('channels')
+            self.rawBytes = data.get('frames')
+            # 双声道 / 单声道
+            self.pcmData = data.get('pcm_data')
+            # 拆分通道
+            if self.numChannels > 1:
+                self.pcmData = self.pcmData.T
+
+            self.startTime = time.time()
+            self.lastOffset = 0
+
+        except Exception as e:
+            self.ReleasePcmData()
+
+    def ReleasePcmData(self):
+        if self.pcmData is not None:
+            del self.pcmData
+            self.pcmData = None
+        self.rawBytes = b''  # 清空字节缓存
+
+    def GetRms(self) -> float:
+        """
+        获取当前音频响度
+        """
+        return self.currentRms
+    
+    def calculate_rms(self, data: bytes) -> float:
+        """计算RMS音量标准--肥波佬提供"""
+        length = len(data) / 2
+        shorts = struct.unpack("%dh" % length, data)
+        sum_squares = 0.0
+        for sample in shorts:
+            n = sample * (1.0 / 32768)
+            sum_squares += n * n
+        rms = np.sqrt(sum_squares / length)
+        return rms
+
+    def Update(self) -> bool:
+        """
+        更新位置
+        """
+        # 数据未加载或者数据已经读取完毕
+        if not self.rawBytes or self.lastOffset >= self.numFrames:
+            return False
+
+        currentTime = time.time() - self.startTime
+        currentOffset = int(currentTime * self.sampleRate)
+
+        # 时间太短
+        if currentOffset <= self.lastOffset:
+            return True
+
+        currentOffset = min(currentOffset, self.numFrames)
+
+        # 计算当前片段对应的字节位置
+        bytes_per_frame = self.sampleWidth * self.numChannels
+        start_byte = self.lastOffset * bytes_per_frame
+        end_byte = currentOffset * bytes_per_frame
+        
+        # 提取当前音频片段的字节数据
+        audio_bytes = self.rawBytes[start_byte:end_byte]
+        
+        # 使用提供的RMS函数计算响度
+        if audio_bytes:
+            self.currentRms = min(1.0, self.calculate_rms(audio_bytes) * 3.0)
+        else:
+            self.currentRms = 0.0
+
+        self.lastOffset = currentOffset
+        return True
\ No newline at end of file
diff --git a/py-my-neuro/live2d_model.py b/py-my-neuro/live2d_model.py
new file mode 100644
index 0000000..8a8cd81
--- /dev/null
+++ b/py-my-neuro/live2d_model.py
@@ -0,0 +1,582 @@
+"""
+Live2D模型控制器 - 负责显示和控制Live2D模型
+"""
+
+import os
+import sys
+import time
+import win32gui
+import win32con
+import OpenGL.GL as gl
+import logging
+from PyQt5.QtCore import Qt
+from PyQt5.QtGui import QCursor, QSurfaceFormat
+from PyQt5.QtWidgets import QOpenGLWidget, QApplication
+from PyQt5.QtGui import QGuiApplication
+
+import live2d.v3 as live2d
+from live2d.v3 import StandardParams
+from models.lipsync import WavHandler
+import numpy as np
+
+logger = logging.getLogger("live2d_model")
+
+class Live2DModel(QOpenGLWidget):
+    """Live2D模型控制器类，继承自QOpenGLWidget"""
+
+    def __init__(self, config=None, event_bus=None):
+        """初始化Live2D模型控制器
+        
+        Args:
+            config: 配置信息
+            event_bus: 事件总线
+        """
+        super().__init__()
+        
+        # 保存配置和事件总线
+        self.config = config or {}
+        self.event_bus = event_bus
+        
+        # 从配置获取模型路径和设置
+        self.model_path = self.config.get("ui", {}).get("model_path", "")
+        self.model_scale = self.config.get("ui", {}).get("model_scale", 1.0)
+        
+        # 窗口初始化设置
+        self.setWindowFlags(
+            Qt.WindowType.FramelessWindowHint | 
+            Qt.WindowType.Tool | 
+            Qt.WindowType.WindowStaysOnTopHint
+        )  # 无边框窗口，任务栏不显示图标，永远置顶
+        self.setAttribute(Qt.WA_TranslucentBackground, True)  # 透明背景
+        
+        # 设置分层窗口和初始穿透属性
+        self.hwnd = int(self.winId())
+        win32gui.SetWindowLong(
+            self.hwnd,
+            win32con.GWL_EXSTYLE,
+            win32gui.GetWindowLong(self.hwnd, win32con.GWL_EXSTYLE) | 
+            win32con.WS_EX_LAYERED | 
+            win32con.WS_EX_TRANSPARENT
+        )
+        win32gui.SetLayeredWindowAttributes(self.hwnd, 0, 255, win32con.LWA_ALPHA)
+        
+        # 模型位置偏移量
+        self.model_offset_x = 0
+        self.model_offset_y = 0
+        self.drag_mode = 0  # 0为移动窗口模型，1为移动模型模式
+        
+        # 窗口状态
+        self.isInModelArea = False  # 鼠标是否在模型区域内
+        self.isClickingModel = False  # 是否正在点击模型
+        self.screen_size = QGuiApplication.primaryScreen().geometry()
+        self.window_size = (1000, 1000)
+        
+        # 根据拖拽模式不同设置窗口大小和位置
+        if self.drag_mode:
+            self.resize(self.screen_size.width()+1, self.screen_size.height())
+            # 将窗口移动到中心位置
+            self.move(
+                (self.screen_size.width()-self.frameGeometry().width())//2, 
+                (self.screen_size.height()-self.frameGeometry().height())//2
+            )
+        else:
+            self.resize(self.window_size[0], self.window_size[1])  # 窗口大小
+            self.move(
+                (self.screen_size.width()-self.frameGeometry().width())//2, 
+                (self.screen_size.height()-self.frameGeometry().height())//2
+            )
+        
+        # 鼠标和缩放相关
+        self.is_pressed = False
+        self.scale = self.model_scale  # 使用配置中的缩放比例
+        self.clickX = -1
+        self.clickY = -1
+        self.drag_start_offset_x = 0
+        self.drag_start_offset_y = 0
+        
+        # 显示系统缩放比例
+        self.systemScale = QGuiApplication.primaryScreen().devicePixelRatio()
+        
+        # Live2D模型相关
+        self.model = None  # 存储Live2D模型实例
+        self.wav_handler = None # 口型匹配
+        self.is_talking = False  # 是否正在说话
+        self.is_listening = False  # 是否正在聆听
+        self.current_expression = ""  # 当前表情
+        
+        logger.info("Live2D模型控制器初始化完成")
+    
+    def initializeGL(self):
+        """初始化OpenGL和加载Live2D模型"""
+        try:
+            # 将当前窗口作为OpenGL上下文
+            self.makeCurrent()
+            
+            # 初始化Live2D
+            if hasattr(live2d, 'LIVE2D_VERSION') and live2d.LIVE2D_VERSION == 3:
+                try:
+                    live2d.glInit()  # 初始化OpenGL(仅限Live2D v3)
+                    logger.info("Live2D glInit 成功")
+                except Exception as e:
+                    logger.error(f"Live2D glInit 失败: {e}")
+            
+            # 创建模型实例
+            try:
+                self.model = live2d.LAppModel()
+                self.wav_handler = WavHandler()
+                logger.info("Live2D 模型实例创建成功")
+            except Exception as e:
+                logger.error(f"Live2D 模型实例创建失败: {e}")
+                raise
+
+            # 加载模型
+            model_loaded = False
+            # 加载模型
+            if self.model_path and os.path.exists(self.model_path):
+                try:
+                    self.model.LoadModelJson(self.model_path)
+                    logger.info(f"从配置路径加载模型成功: {self.model_path}")
+                    model_loaded = True
+                except Exception as e:
+                    logger.error(f"从配置路径加载模型失败: {self.model_path}, 错误: {e}")
+
+            if not model_loaded and hasattr(live2d, 'LIVE2D_VERSION') and live2d.LIVE2D_VERSION == 3:
+                # 尝试加载2D文件夹中的模型
+                for root, dirs, files in os.walk("models/2D"):
+                    for file in files:
+                        # 检查文件是否以 .model3.json 结尾
+                        if file.endswith('.model3.json'):
+                            # 构建完整文件路径并添加到结果列表
+                            full_path = os.path.join(root, file)
+                            print(full_path)
+                
+                if os.path.exists(full_path):
+                    try:
+                        self.model.LoadModelJson(full_path)
+                        logger.info(f"从2D文件夹加载模型成功: {full_path}")
+                        model_loaded = True
+                    except Exception as e:
+                        logger.error(f"从2D文件夹加载模型失败: {full_path}, 错误: {e}")
+                
+                if not model_loaded:
+                    logger.warning("未能加载任何模型")
+            
+            # 设置模型缩放
+            if self.model:
+                self.model.SetScale(self.scale)
+            
+            # 启动高帧率定时器
+            self.startTimer(int(1000 / 60))  # 启动60FPS定时器
+            
+            logger.info("Live2D模型初始化完成")
+        
+        except Exception as e:
+            logger.error(f"初始化Live2D模型失败: {e}")
+            import traceback
+            logger.error(traceback.format_exc())
+    
+    def resizeGL(self, width, height):
+        """窗口大小改变时调整模型参数"""
+        if self.model:
+            self.model.Resize(width, height)
+    
+    def paintGL(self):
+        """每帧渲染模型"""
+        try:
+            # 清空OpenGL缓冲区
+            live2d.clearBuffer()
+            
+            if self.model:
+                # 更新模型参数(物理、动作等)
+                self.model.Update()
+
+                if self.wav_handler.Update():
+                    # 利用 wav 响度更新 嘴部张合
+                    self.model.SetParameterValue(
+                        StandardParams.ParamMouthOpenY, self.wav_handler.GetRms()
+                    )
+                
+                # # 如果模型动作结束，根据当前状态触发不同动作
+                # if self.model.IsMotionFinished():
+                #     if self.is_talking:
+                #         # 如果正在说话，播放说话动作
+                #         self.model.StartMotion("Talk", 0, 2)
+                #     elif self.is_listening:
+                #         # 如果正在聆听，播放聆听动作
+                #         self.model.StartMotion("Listen", 0, 2)
+                #     else:
+                #         # 否则播放随机动作
+                #         # self.model.StartRandomMotion()
+                #         pass
+                
+                # 绘制模型
+                self.model.Draw()
+        
+        except Exception as e:
+            logger.error(f"渲染模型失败: {e}")
+    
+    def timerEvent(self, event):
+        """定时器事件，用于更新模型状态和窗口交互"""
+        if not self.isVisible():
+            return
+        
+        try:
+            # 获取当前窗口样式
+            current_style = win32gui.GetWindowLong(self.hwnd, win32con.GWL_EXSTYLE)
+            
+            # 获取鼠标相对于窗口的位置
+            local_x, local_y = QCursor.pos().x() - self.x(), QCursor.pos().y() - self.y()
+            
+            # 如果不是拖拽模式，将鼠标位置传递给模型
+            if not self.drag_mode and self.model:
+                self.model.Drag(local_x, local_y)
+            
+            # 检查鼠标是否在模型区域内 - 修改方法名以避免与属性冲突
+            in_model_area = self.check_in_model_area(local_x, local_y)
+            
+            # 更新窗口穿透属性
+            if in_model_area:
+                # 鼠标在模型区域内，禁用穿透
+                new_style = current_style & ~win32con.WS_EX_TRANSPARENT
+                self.isInModelArea = True
+            else:
+                # 鼠标不在模型区域内，启用穿透
+                new_style = current_style | win32con.WS_EX_TRANSPARENT
+                self.isInModelArea = False
+            
+            # 如果样式发生变化，更新窗口属性
+            if new_style != current_style:
+                win32gui.SetWindowLong(self.hwnd, win32con.GWL_EXSTYLE, new_style)
+                win32gui.SetLayeredWindowAttributes(self.hwnd, 0, 255, win32con.LWA_ALPHA)
+            
+            # 请求重绘
+            self.update()
+        
+        except Exception as e:
+            logger.error(f"定时器事件处理失败: {e}")
+
+    def check_in_model_area(self, x, y):
+        """判断坐标是否在模型区域内
+        
+        Args:
+            x: 相对于窗口的X坐标
+            y: 相对于窗口的Y坐标
+                
+        Returns:
+            是否在模型区域内
+        """
+        try:
+            # 计算OpenGL坐标
+            gl_x = int(x * self.systemScale)
+            gl_y = int((self.height() - y) * self.systemScale)
+            
+            # 检查坐标是否在窗口范围内
+            if (gl_x < 0 or gl_y < 0 or 
+                gl_x >= self.width() * self.systemScale or 
+                gl_y >= self.height() * self.systemScale):
+                return False
+            
+            # 读取像素的Alpha通道值
+            alpha = gl.glReadPixels(gl_x, gl_y, 1, 1, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE)[3]
+            
+            # 如果Alpha值大于阈值，则认为在模型区域内
+            return alpha > 50
+        
+        except Exception as e:
+            logger.error(f"判断模型区域失败: {e}")
+            return False
+    
+    def mousePressEvent(self, event):
+        """鼠标按下事件
+        
+        Args:
+            event: 鼠标事件
+        """
+        x, y = event.localPos().x(), event.localPos().y()
+        
+        # 判断点击是否在模型区域
+        if self.check_in_model_area(x, y):
+            self.isClickingModel = True
+            self.clickX, self.clickY = x, y  # 记录点击位置
+            self.is_pressed = True
+            
+            # 记录按下时的初始偏移量
+            self.drag_start_offset_x = self.model_offset_x
+            self.drag_start_offset_y = self.model_offset_y
+            
+            logger.debug("模型被点击")
+    
+    def mouseReleaseEvent(self, event):
+        """鼠标释放事件
+        
+        Args:
+            event: 鼠标事件
+        """
+        if self.drag_mode:
+            # 拖拽模式下，结束拖拽
+            self.isClickingModel = False
+            self.is_pressed = False
+        else:
+            # 非拖拽模式下，处理点击
+            x, y = event.localPos().x(), event.localPos().y()
+            if self.is_pressed or self.isInModelArea:
+                if self.model:
+                    self.model.Drag(x, y)
+                self.isClickingModel = False
+                self.is_pressed = False
+        
+        logger.debug("鼠标释放")
+    
+    def mouseMoveEvent(self, event):
+        """鼠标移动事件
+        
+        Args:
+            event: 鼠标事件
+        """
+        x, y = event.localPos().x(), event.localPos().y()
+        
+        # 只有当点击了模型区域时才处理移动
+        if self.isClickingModel:
+            if self.drag_mode:
+                # 拖拽模式：移动模型
+                # 计算鼠标移动的增量（考虑系统缩放比例）
+                dx = (x - self.clickX) / self.systemScale
+                dy = (y - self.clickY) / self.systemScale
+                
+                # 更新模型偏移量
+                self.model_offset_x = self.drag_start_offset_x + dx
+                self.model_offset_y = self.drag_start_offset_y + dy
+                
+                # 设置模型偏移
+                if self.model:
+                    canvas_w, canvas_h = self.model.GetCanvasSize()
+                    # 设置模型偏移（Y轴方向可能需要取反，根据实际效果调整）
+                    self.model.SetOffset(
+                        (self.model_offset_x - canvas_w/2)/(self.screen_size.height()/2),
+                        (-self.model_offset_y + canvas_h/2)/(self.screen_size.height()/2)
+                    )
+            else:
+                # 非拖拽模式：移动窗口
+                self.move(int(self.x() + x - self.clickX), int(self.y() + y - self.clickY))
+    
+    def wheelEvent(self, event):
+        """鼠标滚轮事件，用于缩放模型
+        
+        Args:
+            event: 滚轮事件
+        """
+        delta = event.angleDelta().y()
+        
+        # 根据滚轮方向缩放模型
+        new_scale = self.scale * (1.07 if delta > 0 else 0.93)
+        
+        # 应用新的缩放比例
+        if new_scale != self.scale:
+            self.scale = new_scale
+            if self.model:
+                self.model.SetScale(self.scale)
+            
+            logger.debug(f"模型缩放比例: {self.scale}")
+
+    def set_talking(self, is_talking):
+        """设置说话状态
+        
+        Args:
+            is_talking: 是否正在说话
+        """
+        self.is_talking = is_talking
+        logger.debug(f"设置说话状态: {is_talking}")
+        
+        # if self.model:
+        #     try:
+        #         if is_talking:
+        #             # 可以触发说话相关动作
+        #             self.model.StartMotion("Talk", 0, 2)  # 假设有一个名为"Talk"的动作组
+        #         else:
+        #             # 当不说话时，如果在聆听则播放聆听动作，否则播放随机动作
+        #             if self.is_listening:
+        #                 self.model.StartMotion("Listen", 0, 2)
+        #             else:
+        #                 # self.model.StartRandomMotion()
+        #                 pass
+                
+        #         logger.debug(f"设置说话状态: {is_talking}")
+        #     except Exception as e:
+        #         logger.error(f"设置说话状态失败: {e}")
+    
+    def set_listening(self, is_listening):
+        """设置聆听状态
+        
+        Args:
+            is_listening: 是否正在聆听
+        """
+        self.is_listening = is_listening
+        logger.debug(f"设置聆听状态: {is_listening}")
+        
+        # if self.model:
+        #     try:
+        #         if is_listening and not self.is_talking:
+        #             # 如果不在说话，触发聆听相关动作
+        #             self.model.StartMotion("Listen", 0, 2)  # 假设有一个名为"Listen"的动作组
+        #         elif not is_listening and not self.is_talking:
+        #             # 如果既不聆听也不说话，播放随机动作
+        #             # self.model.StartRandomMotion()
+        #             pass
+                
+        #         logger.debug(f"设置聆听状态: {is_listening}")
+        #     except Exception as e:
+        #         logger.error(f"设置聆听状态失败: {e}")
+    
+    def set_expression(self, expression):
+        """设置表情
+        
+        Args:
+            expression: 表情名称
+        """
+        if self.model:
+            try:
+                # 设置表情
+                self.model.SetExpression(expression)
+                self.current_expression = expression
+                
+                logger.debug(f"设置表情: {expression}")
+            except Exception as e:
+                logger.error(f"设置表情失败: {e}")
+    
+    def set_random_expression(self):
+        """设置随机表情"""
+        if self.model:
+            try:
+                # 设置随机表情
+                expression = self.model.SetRandomExpression()
+                self.current_expression = expression
+                
+                logger.debug(f"设置随机表情: {expression}")
+                return expression
+            except Exception as e:
+                logger.error(f"设置随机表情失败: {e}")
+                return None
+    
+    def reset_expression(self):
+        """重置为默认表情"""
+        if self.model:
+            try:
+                # 重置表情
+                self.model.ResetExpression()
+                self.current_expression = ""
+                
+                logger.debug("重置为默认表情")
+            except Exception as e:
+                logger.error(f"重置表情失败: {e}")
+    
+    def get_available_expressions(self):
+        """获取可用的表情列表
+        
+        Returns:
+            表情ID列表
+        """
+        if self.model:
+            try:
+                # 获取表情列表
+                expressions = self.model.GetExpressionIds()
+                return expressions
+            except Exception as e:
+                logger.error(f"获取表情列表失败: {e}")
+        
+        return []
+    
+    def get_available_motions(self):
+        """获取可用的动作组和数量
+        
+        Returns:
+            动作组字典 {组名: 动作数量}
+        """
+        if self.model:
+            try:
+                # 获取动作组字典
+                motions = self.model.GetMotionGroups()
+                return motions
+            except Exception as e:
+                logger.error(f"获取动作组失败: {e}")
+        
+        return {}
+    
+    def toggle_auto_breath(self, enable=True):
+        """切换自动呼吸功能
+        
+        Args:
+            enable: 是否启用
+        """
+        if self.model:
+            try:
+                # 设置自动呼吸
+                self.model.SetAutoBreathEnable(enable)
+                
+                logger.debug(f"设置自动呼吸: {enable}")
+            except Exception as e:
+                logger.error(f"设置自动呼吸失败: {e}")
+    
+    def toggle_auto_blink(self, enable=True):
+        """切换自动眨眼功能
+        
+        Args:
+            enable: 是否启用
+        """
+        if self.model:
+            try:
+                # 设置自动眨眼
+                self.model.SetAutoBlinkEnable(enable)
+                
+                logger.debug(f"设置自动眨眼: {enable}")
+            except Exception as e:
+                logger.error(f"设置自动眨眼失败: {e}")
+
+# 初始化和清理Live2D
+def init_live2d():
+    """初始化Live2D引擎"""
+    try:
+        live2d.init()
+        logger.info("Live2D引擎初始化完成")
+        return True
+    except Exception as e:
+        logger.error(f"初始化Live2D引擎失败: {e}")
+        return False
+
+def dispose_live2d():
+    """清理Live2D引擎"""
+    try:
+        live2d.dispose()
+        logger.info("Live2D引擎清理完成")
+        return True
+    except Exception as e:
+        logger.error(f"清理Live2D引擎失败: {e}")
+        return False
+
+# 示例用法
+if __name__ == "__main__":
+    # 设置日志
+    logging.basicConfig(level=logging.DEBUG)
+    
+    # 初始化Live2D引擎
+    init_live2d()
+    
+    # 初始化QT应用
+    app = QApplication(sys.argv)
+    
+    # 设置垂直同步
+    format = QSurfaceFormat.defaultFormat()
+    format.setSwapInterval(0)  # 0禁用垂直同步，1启用
+    QSurfaceFormat.setDefaultFormat(format)
+    
+    # 创建Live2D模型窗口
+    model = Live2DModel()
+    model.show()
+    
+    # 运行应用
+    exit_code = app.exec()
+    
+    # 清理Live2D引擎
+    dispose_live2d()
+    
+    # 退出应用
+    sys.exit(exit_code)
\ No newline at end of file
diff --git "a/py-my-neuro/\345\215\240\344\275\215.txt" "b/py-my-neuro/\345\215\240\344\275\215.txt"
new file mode 100644
index 0000000..e69de29
diff --git "a/tts-studio/\345\243\260\351\237\263\346\250\241\345\236\213\345\212\240\345\267\245\345\216\202/\344\270\200\351\224\256\345\212\240\345\267\245.bat" "b/tts-studio/\345\243\260\351\237\263\346\250\241\345\236\213\345\212\240\345\267\245\345\216\202/\344\270\200\351\224\256\345\212\240\345\267\245.bat"
index 7ad15b7..cf72e75 100644
--- "a/tts-studio/\345\243\260\351\237\263\346\250\241\345\236\213\345\212\240\345\267\245\345\216\202/\344\270\200\351\224\256\345\212\240\345\267\245.bat"
+++ "b/tts-studio/\345\243\260\351\237\263\346\250\241\345\236\213\345\212\240\345\267\245\345\216\202/\344\270\200\351\224\256\345\212\240\345\267\245.bat"
@@ -1,8 +1,8 @@
 @echo off
 chcp 936
-echo ڿʼ...
+echo 正在开始...
 cd /d %~dp0
-call ..\..\my-neuro-env\Scripts\activate.bat
-python .py
-echo ִ
-pause
\ No newline at end of file
+call conda activate my-neuro
+python 处理.py
+echo 执行完成
+pause
diff --git "a/tts-studio/\345\243\260\351\237\263\346\250\241\345\236\213\345\212\240\345\267\245\345\216\202/\345\244\204\347\220\206.py" "b/tts-studio/\345\243\260\351\237\263\346\250\241\345\236\213\345\212\240\345\267\245\345\216\202/\345\244\204\347\220\206.py"
index d2cf50a..019474b 100644
--- "a/tts-studio/\345\243\260\351\237\263\346\250\241\345\236\213\345\212\240\345\267\245\345\216\202/\345\244\204\347\220\206.py"
+++ "b/tts-studio/\345\243\260\351\237\263\346\250\241\345\236\213\345\212\240\345\267\245\345\216\202/\345\244\204\347\220\206.py"
@@ -4,75 +4,77 @@ import os
 import glob
 import subprocess
 
+
 def main():
     # 获取当前目录作为搜索路径
     current_dir = os.path.dirname(os.path.abspath(__file__))
-    
+
     # 在当前目录下查找pth模型文件
     pth_files = glob.glob(os.path.join(current_dir, "*.pth"))
-    
+
     if not pth_files:
         print("错误: 当前目录下未找到pth模型文件!")
         print("请将pth模型文件放在当前脚本所在目录下")
         return
-    
+
     model_path = pth_files[0]
     print(f"找到模型文件: {os.path.basename(model_path)}")
-    
+
     # 在当前目录下查找wav音频文件
     wav_files = glob.glob(os.path.join(current_dir, "*.wav"))
-    
+
     if not wav_files:
         print("错误: 当前目录下未找到wav音频文件!")
         print("请将wav音频文件放在当前脚本所在目录下")
         return
-    
+
     # 直接使用找到的第一个wav文件
     reference_audio = wav_files[0]
     print(f"\n找到参考音频文件: {os.path.basename(reference_audio)}")
-    
+
     # 获取用户输入
     print("\n请输入以下信息生成TTS命令:")
-    
+
     # 默认值
     default_device = "cuda"
     default_port = "5000"
     default_language = "zh"
-    
+
     # 获取文本内容
     text = input("请输入要合成的文本内容: ")
     if not text:
         print("错误: 文本内容不能为空!")
         return
-    
+
     # 语言选项及说明
     print("\n可选语言代码:")
     print("  zh - 中文")
     print("  en - 英文")
     print("  ja - 日语")
     print("  ko - 韩语")
-    
+
     # 获取语言
     language = input(f"请输入语言代码 (默认: {default_language}): ") or default_language
-    
+
     # 生成命令
     cmd = (f"python tts_api.py -p {default_port} -d {default_device} "
            f"-s {model_path} -dr {reference_audio} -dt \"{text}\" -dl {language}")
-    
+
     # 创建bat文件
     bat_filename = "你的TTS.bat"
     bat_path = os.path.join(current_dir, bat_filename)
-    
+
     # 写入bat文件内容 - 使用ANSI编码
     with open(bat_path, "w", encoding="gbk") as bat_file:
         bat_file.write("@echo off\n")
-        bat_file.write(f"call ..\\..\\my-neuro-env\\Scripts\\activate.bat\n")
+        bat_file.write("call conda activate my-neuro\n")
         bat_file.write("cd ..\n")  # 添加返回上一级目录的命令
         bat_file.write(f"{cmd}\n")
         bat_file.write("pause\n")
-    
+
     print(f"\n已生成批处理文件: {bat_filename}")
     print("您可以双击此文件执行TTS命令")
 
+
 if __name__ == "__main__":
-    main()
\ No newline at end of file
+    main()
